class YOLO(nn.Module):
    def __init__(self):
        super(YOLO, self).__init__()
        
        self.pre_train_net = nn.Sequential(
            ################
            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3), # Conv 1
            nn.LeakyReLU(negative_slope=0.01),
            nn.MaxPool2d(kernel_size=2,stride=2), # Max Pool 1
            
            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1), # Conv 2
            nn.LeakyReLU(negative_slope=0.01),
            nn.MaxPool2d(kernel_size=2,stride=2), # Max Pool 2            

            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=1, padding=0), # Conv 3
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1), # Conv 4
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, padding=0), # Conv 5
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), # Conv 6
            nn.LeakyReLU(negative_slope=0.01),
            nn.MaxPool2d(kernel_size=2,stride=2), # Max Pool 3  
            
            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, padding=0), # Conv 7
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), # Conv 8
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, padding=0), # Conv 9
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), # Conv 10
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, padding=0), # Conv 11
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), # Conv 12
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, padding=0), # Conv 13
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), # Conv 14
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, padding=0), # Conv 15
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1), # Conv 16
            nn.LeakyReLU(negative_slope=0.01),            
            nn.MaxPool2d(kernel_size=2,stride=2), # Max Pool 4    
            
            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, padding=0), # Conv 17
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1), # Conv 18
            nn.LeakyReLU(negative_slope=0.01)
            ################
        )
        
        self.post_net = nn.Sequential(
            ################
            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1), # Conv 19
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=2, padding=1), # Conv 20
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1), # Conv 21
            nn.LeakyReLU(negative_slope=0.01),
            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1), # Conv 22
            nn.LeakyReLU(negative_slope=0.01)
            ################
        )
        
        self.FC1 = nn.Sequential(
            nn.Linear(50176, 4096),
            nn.LeakyReLU(),
            nn.Dropout()
        )
        
        self.FC2 = nn.Sequential(
            nn.Linear(4096, 1470)
        )
        
        self.pre_train_net.cuda()
        self.post_net.cuda()
        self.FC1.cuda()
        self.FC2.cuda()
        
        self._initialize_weights()

    def forward(self, x):
        output = self.pre_train_net(x)
        output = self.post_net(output)

        # Ready to going for FC layer
        output = output.view(output.size(0), -1)

        output = self.FC1(output)
        output = self.FC2(output)

        output = output.view(output.size(0), 7, 7, 30)
        # Converting the output shape to the (batch_size, 7, 7, 30)
        output = F.relu(output)

        return output
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.Linear):
                m.weight.data.normal_(0, 0.01)
                m.bias.data.zero_()
