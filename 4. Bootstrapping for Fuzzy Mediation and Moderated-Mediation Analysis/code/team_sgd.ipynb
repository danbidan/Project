{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSiX-tbAlNsJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from scipy import stats\n",
        "from scipy.stats import t, f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import skew, kurtosis"
      ],
      "metadata": {
        "id": "sg20jSLjlU2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "random_seed = 2\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)"
      ],
      "metadata": {
        "id": "L_ponYWGlU9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('teams.csv')"
      ],
      "metadata": {
        "id": "RqngIXuIlVEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=data['dysfunc']\n",
        "xdf=pd.DataFrame({'a':df-0.05,'b':df,'c':df+0.05})\n",
        "x=xdf.to_numpy()\n",
        "net=data['negtone']\n",
        "mdf=pd.DataFrame({'a':net-0.05,'b':net,'c':net+0.05})\n",
        "m=mdf.to_numpy()\n",
        "per=data['perform']\n",
        "ydf=pd.DataFrame({'a':per-0.05,'b':per,'c':per+0.05})\n",
        "y=ydf.to_numpy()\n"
      ],
      "metadata": {
        "id": "QNLuwKxZl-vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IExPQa0bdJ7"
      },
      "outputs": [],
      "source": [
        "def gpbdl1(data):\n",
        "  df=data['dysfunc']\n",
        "  xdf=pd.DataFrame({'a':df-0.05,'b':df,'c':df+0.05})\n",
        "  x=xdf.to_numpy()\n",
        "  net=data['negtone']\n",
        "  mdf=pd.DataFrame({'a':net-0.05,'b':net,'c':net+0.05})\n",
        "  m=mdf.to_numpy()\n",
        "  per=data['perform']\n",
        "  ydf=pd.DataFrame({'a':per-0.05,'b':per,'c':per+0.05})\n",
        "  y=ydf.to_numpy()\n",
        "  X_l = []\n",
        "  X_m = []\n",
        "  X_r = []\n",
        "\n",
        "  M_l = []\n",
        "  M_m = []\n",
        "  M_r = []\n",
        "\n",
        "  Y_l = []\n",
        "  Y_m = []\n",
        "  Y_r = []\n",
        "  for i in range(len(data)):\n",
        "    X_l.append(x[i][0])\n",
        "    X_m.append(x[i][1])\n",
        "    X_r.append(x[i][2])\n",
        "  for i in range(len(data)):\n",
        "    M_l.append(m[i][0])\n",
        "    M_m.append(m[i][1])\n",
        "    M_r.append(m[i][2])\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    Y_l.append(y[i][0])\n",
        "    Y_m.append(y[i][1])\n",
        "    Y_r.append(y[i][2])\n",
        "\n",
        "\n",
        "  ep = 800\n",
        "  x_train = torch.FloatTensor([X_l])\n",
        "  x_train = x_train.T\n",
        "  y_train = torch.FloatTensor([M_l])\n",
        "  y_train = y_train.T\n",
        "  Weight_l = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_l = torch.zeros(1, requires_grad=True)\n",
        "  w_l=torch.zeros((9,1))\n",
        "  b_l=torch.zeros((9,1))\n",
        "  i=0\n",
        "  # optimizer 설정\n",
        "  optimizer = optim.SGD([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "  nb_epochs = ep  # epoch\n",
        "\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i]= Weight_l\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        "\n",
        "  x_train = torch.FloatTensor([X_m])\n",
        "  x_train = x_train.T\n",
        "  x_train.shape\n",
        "  y_train = torch.FloatTensor([M_m]) # M\n",
        "  y_train = y_train.T\n",
        "  Weight_m = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_m = torch.zeros(1, requires_grad=True)\n",
        "  w_m=torch.zeros((9,1))\n",
        "  b_m=torch.zeros((9,1))\n",
        "  i=0\n",
        "  optimizer = optim.SGD([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i]= Weight_m\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        "  x_train = torch.FloatTensor([X_r])\n",
        "  x_train = x_train.T\n",
        "  x_train.shape\n",
        "  y_train = torch.FloatTensor([M_r]) # M\n",
        "  y_train = y_train.T\n",
        "  Weight_r = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_r = torch.zeros(1, requires_grad=True)\n",
        "  w_r=torch.zeros((9,1))\n",
        "  b_r=torch.zeros((9,1))\n",
        "  i=0\n",
        "  optimizer = optim.SGD([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_r[i]= Weight_r\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        "  w1=(w_l + w_m + w_r)/ 3\n",
        "  b1=(b_l + b_m + b_r)/ 3\n",
        "\n",
        "\n",
        "  x_train = torch.FloatTensor([X_l,M_l])\n",
        "  x_train = x_train.T\n",
        "  y_train = torch.FloatTensor([Y_l])\n",
        "  y_train = y_train.T\n",
        "  Weight_l = torch.zeros((2,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_l = torch.zeros(1, requires_grad=True)\n",
        "  w_l=torch.zeros((9,2))\n",
        "  b_l=torch.zeros((9,1))\n",
        "  i=0\n",
        "  # optimizer 설정\n",
        "  optimizer = optim.SGD([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "  nb_epochs = ep  # epoch\n",
        "\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i][0]= Weight_l[0]\n",
        "      w_l[i][1]= Weight_l[1]\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        "\n",
        "  x_train = torch.FloatTensor([X_m,M_m])\n",
        "  x_train = x_train.T\n",
        "  x_train.shape\n",
        "  y_train = torch.FloatTensor([Y_m]) # M\n",
        "  y_train = y_train.T\n",
        "  Weight_m = torch.zeros((2,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_m = torch.zeros(1, requires_grad=True)\n",
        "  w_m=torch.zeros((9,2))\n",
        "  b_m=torch.zeros((9,1))\n",
        "  i=0\n",
        "  optimizer = optim.SGD([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i][0]= Weight_m[0]\n",
        "      w_m[i][1]= Weight_m[1]\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        "  x_train = torch.FloatTensor([X_r,M_r])\n",
        "  x_train = x_train.T\n",
        "  x_train.shape\n",
        "  y_train = torch.FloatTensor([Y_r]) # M\n",
        "  y_train = y_train.T\n",
        "  Weight_r = torch.zeros((2,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_r = torch.zeros(1, requires_grad=True)\n",
        "  w_r=torch.zeros((9,2))\n",
        "  b_r=torch.zeros((9,1))\n",
        "  i=0\n",
        "  optimizer = optim.SGD([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_r[i][0]= Weight_r[0]\n",
        "      w_r[i][1]= Weight_r[1]\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        "  w2=(w_l + w_m + w_r)/ 3\n",
        "  b2=(b_l + b_m + b_r)/ 3\n",
        "\n",
        "  x_train = torch.FloatTensor([X_l])\n",
        "  x_train = x_train.T\n",
        "  y_train = torch.FloatTensor([Y_l])\n",
        "  y_train = y_train.T\n",
        "  Weight_l = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_l = torch.zeros(1, requires_grad=True)\n",
        "  w_l=torch.zeros((9,1))\n",
        "  b_l=torch.zeros((9,1))\n",
        "  i=0\n",
        "  # optimizer 설정\n",
        "  optimizer = optim.SGD([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i]= Weight_l\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        "\n",
        "  x_train = torch.FloatTensor([X_m])\n",
        "  x_train = x_train.T\n",
        "  y_train = torch.FloatTensor([Y_m])\n",
        "  y_train = y_train.T\n",
        "  Weight_m = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_m = torch.zeros(1, requires_grad=True)\n",
        "  w_m=torch.zeros((9,1))\n",
        "  b_m=torch.zeros((9,1))\n",
        "  i=0\n",
        "  optimizer = optim.SGD([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산ssssssssssssssssssssssssssss\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i]= Weight_m\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        "  x_train = torch.FloatTensor([X_r])\n",
        "  x_train = x_train.T\n",
        "  y_train = torch.FloatTensor([Y_r])\n",
        "  y_train = y_train.T\n",
        "  Weight_r = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        "  Bias_r = torch.zeros(1, requires_grad=True)\n",
        "  w_r=torch.zeros((9,1))\n",
        "  b_r=torch.zeros((9,1))\n",
        "  i=0\n",
        "  optimizer = optim.SGD([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "  for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "  if epoch % 100 ==0:\n",
        "      w_r[i]= Weight_r\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        "  w3=(w_l + w_m + w_r)/ 3\n",
        "  b3=(b_l + b_m + b_r)/ 3\n",
        "  return w1,b1,w2,b2,w3,b3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g=gpbdl1(data)\n",
        "g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNkx0J0VmJFy",
        "outputId": "ddb75554-e924-4124-8e1f-810c17632fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0017],\n",
              "         [0.1511],\n",
              "         [0.2627],\n",
              "         [0.3475],\n",
              "         [0.4122],\n",
              "         [0.4615],\n",
              "         [0.4991],\n",
              "         [0.5277],\n",
              "         [0.5496]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0009],\n",
              "         [0.0379],\n",
              "         [0.0391],\n",
              "         [0.0364],\n",
              "         [0.0340],\n",
              "         [0.0320],\n",
              "         [0.0305],\n",
              "         [0.0294],\n",
              "         [0.0285]], grad_fn=<DivBackward0>),\n",
              " tensor([[ 3.1087e-04, -2.1545e-03],\n",
              "         [ 4.1358e-02, -1.7050e-01],\n",
              "         [ 9.1742e-02, -2.7442e-01],\n",
              "         [ 1.4224e-01, -3.4149e-01],\n",
              "         [ 1.8873e-01, -3.8680e-01],\n",
              "         [ 2.2971e-01, -4.1880e-01],\n",
              "         [ 2.6494e-01, -4.4231e-01],\n",
              "         [ 2.9478e-01, -4.6016e-01],\n",
              "         [ 3.1983e-01, -4.7407e-01]], grad_fn=<DivBackward0>),\n",
              " tensor([[-0.0006],\n",
              "         [-0.0235],\n",
              "         [-0.0229],\n",
              "         [-0.0212],\n",
              "         [-0.0203],\n",
              "         [-0.0199],\n",
              "         [-0.0199],\n",
              "         [-0.0201],\n",
              "         [-0.0203]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0328],\n",
              "         [0.0177],\n",
              "         [0.0310],\n",
              "         [0.0411],\n",
              "         [0.0488],\n",
              "         [0.0547],\n",
              "         [0.0592],\n",
              "         [0.0626],\n",
              "         [0.0652]], grad_fn=<DivBackward0>),\n",
              " tensor([[ 0.0027],\n",
              "         [-0.0330],\n",
              "         [-0.0374],\n",
              "         [-0.0380],\n",
              "         [-0.0382],\n",
              "         [-0.0383],\n",
              "         [-0.0383],\n",
              "         [-0.0384],\n",
              "         [-0.0384]], grad_fn=<DivBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=[None]*5000\n",
        "c_b1=[None]*5000\n",
        "b_b1=[None]*5000\n",
        "cp_b1=[None]*5000\n",
        "\n",
        "a_b2=[None]*5000\n",
        "c_b2=[None]*5000\n",
        "b_b2=[None]*5000\n",
        "cp_b2=[None]*5000\n",
        "a_b3=[None]*5000\n",
        "c_b3=[None]*5000\n",
        "b_b3=[None]*5000\n",
        "cp_b3=[None]*5000\n",
        "a_b4=[None]*5000\n",
        "c_b4=[None]*5000\n",
        "b_b4=[None]*5000\n",
        "cp_b4=[None]*5000\n",
        "a_b5=[None]*5000\n",
        "c_b5=[None]*5000\n",
        "b_b5=[None]*5000\n",
        "cp_b5=[None]*5000\n",
        "a_b6=[None]*5000\n",
        "c_b6=[None]*5000\n",
        "b_b6=[None]*5000\n",
        "cp_b6=[None]*5000\n",
        "a_b7=[None]*5000\n",
        "c_b7=[None]*5000\n",
        "b_b7=[None]*5000\n",
        "cp_b7=[None]*5000\n",
        "a_b8=[None]*5000\n",
        "c_b8=[None]*5000\n",
        "b_b8=[None]*5000\n",
        "cp_b8=[None]*5000\n",
        "a_b9=[None]*5000\n",
        "c_b9=[None]*5000\n",
        "b_b9=[None]*5000\n",
        "cp_b9=[None]*5000\n",
        "\n",
        "bi1=[None]*5000\n",
        "bi2=[None]*5000\n",
        "bi3=[None]*5000\n",
        "bi4=[None]*5000\n",
        "bi5=[None]*5000\n",
        "bi6=[None]*5000\n",
        "bi7=[None]*5000\n",
        "bi8=[None]*5000\n",
        "bi9=[None]*5000\n",
        "\n",
        "\n",
        "fbi1=[None]*5000\n",
        "fbi2=[None]*5000\n",
        "fbi3=[None]*5000\n",
        "fbi4=[None]*5000\n",
        "fbi5=[None]*5000\n",
        "fbi6=[None]*5000\n",
        "fbi7=[None]*5000\n",
        "fbi8=[None]*5000\n",
        "fbi9=[None]*5000\n",
        "\n",
        "sbi1=[None]*5000\n",
        "sbi2=[None]*5000\n",
        "sbi3=[None]*5000\n",
        "sbi4=[None]*5000\n",
        "sbi5=[None]*5000\n",
        "sbi6=[None]*5000\n",
        "sbi7=[None]*5000\n",
        "sbi8=[None]*5000\n",
        "sbi9=[None]*5000\n"
      ],
      "metadata": {
        "id": "qlQmT07bLxzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "XknFvWtwPdQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#부트스트랩 표본\n",
        "for i in tqdm(range(0,5000)):\n",
        "  new_data=data.sample(n=60,replace=True,random_state=i)\n",
        "  parameters=gpbdl1(new_data)\n",
        "  a_b1[i]= parameters[0][0].detach()\n",
        "  c_b1[i]= parameters[2][0][0].detach()\n",
        "  b_b1[i]= parameters[2][0][1].detach()\n",
        "  cp_b1[i]= parameters[4][0].detach()\n",
        "  a_b2[i]= parameters[0][1].detach()\n",
        "  c_b2[i]= parameters[2][1][0].detach()\n",
        "  b_b2[i]= parameters[2][1][1].detach()\n",
        "  cp_b2[i]= parameters[4][1].detach()\n",
        "  a_b3[i]= parameters[0][2].detach()\n",
        "  c_b3[i]= parameters[2][2][0].detach()\n",
        "  b_b3[i]= parameters[2][2][1].detach()\n",
        "  cp_b3[i]= parameters[4][2].detach()\n",
        "  a_b4[i]= parameters[0][3].detach()\n",
        "  c_b4[i]= parameters[2][3][0].detach()\n",
        "  b_b4[i]= parameters[2][3][1].detach()\n",
        "  cp_b4[i]= parameters[4][3].detach()\n",
        "  a_b5[i]= parameters[0][4].detach()\n",
        "  c_b5[i]= parameters[2][4][0].detach()\n",
        "  b_b5[i]= parameters[2][4][1].detach()\n",
        "  cp_b5[i]= parameters[4][4].detach()\n",
        "  a_b6[i]= parameters[0][5].detach()\n",
        "  c_b6[i]= parameters[2][5][0].detach()\n",
        "  b_b6[i]= parameters[2][5][1].detach()\n",
        "  cp_b6[i]= parameters[4][5].detach()\n",
        "  a_b7[i]= parameters[0][6].detach()\n",
        "  c_b7[i]= parameters[2][6][0].detach()\n",
        "  b_b7[i]= parameters[2][6][1].detach()\n",
        "  cp_b7[i]= parameters[4][6].detach()\n",
        "  a_b8[i]= parameters[0][7].detach()\n",
        "  c_b8[i]= parameters[2][7][0].detach()\n",
        "  b_b8[i]= parameters[2][7][1].detach()\n",
        "  cp_b8[i]= parameters[4][7].detach()\n",
        "  a_b9[i]= parameters[0][8].detach()\n",
        "  c_b9[i]= parameters[2][8][0].detach()\n",
        "  b_b9[i]= parameters[2][8][1].detach()\n",
        "  cp_b9[i]= parameters[4][8].detach()\n",
        "\n",
        "  bi1[i]=parameters[3][0].detach()\n",
        "  bi2[i]=parameters[3][1].detach()\n",
        "  bi3[i]=parameters[3][2].detach()\n",
        "  bi4[i]=parameters[3][3].detach()\n",
        "  bi5[i]=parameters[3][4].detach()\n",
        "  bi6[i]=parameters[3][5].detach()\n",
        "  bi7[i]=parameters[3][6].detach()\n",
        "  bi8[i]=parameters[3][7].detach()\n",
        "  bi9[i]=parameters[3][8].detach()\n",
        "\n",
        "  fbi1[i]=parameters[1][0].detach()\n",
        "  fbi2[i]=parameters[1][1].detach()\n",
        "  fbi3[i]=parameters[1][2].detach()\n",
        "  fbi4[i]=parameters[1][3].detach()\n",
        "  fbi5[i]=parameters[1][4].detach()\n",
        "  fbi6[i]=parameters[1][5].detach()\n",
        "  fbi7[i]=parameters[1][6].detach()\n",
        "  fbi8[i]=parameters[1][7].detach()\n",
        "  fbi9[i]=parameters[1][8].detach()\n",
        "\n",
        "  sbi1[i]=parameters[5][0].detach()\n",
        "  sbi2[i]=parameters[5][1].detach()\n",
        "  sbi3[i]=parameters[5][2].detach()\n",
        "  sbi4[i]=parameters[5][3].detach()\n",
        "  sbi5[i]=parameters[5][4].detach()\n",
        "  sbi6[i]=parameters[5][5].detach()\n",
        "  sbi7[i]=parameters[5][6].detach()\n",
        "  sbi8[i]=parameters[5][7].detach()\n",
        "  sbi9[i]=parameters[5][8].detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "VGICOlo3mJMc",
        "outputId": "3e1ac01f-1b98-42b0-d569-fe9c4fd41d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 2733/5000 [1:45:47<1:27:45,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d420265469de>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mnew_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpbdl1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0ma_b1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mc_b1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-48f8961600ab>\u001b[0m in \u001b[0;36mgpbdl1\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('a_b1',a_b1)\n",
        "np.save('b_b1',b_b1)\n",
        "np.save('c_b1',c_b1)\n",
        "np.save('cp_b1',cp_b1)\n",
        "np.save('a_b2',a_b2)\n",
        "np.save('b_b2',b_b2)\n",
        "np.save('c_b2',c_b2)\n",
        "np.save('cp_b2',cp_b2)\n",
        "np.save('a_b3',a_b3)\n",
        "np.save('b_b3',b_b3)\n",
        "np.save('c_b3',c_b3)\n",
        "np.save('cp_b3',cp_b3)\n",
        "np.save('a_b4',a_b4)\n",
        "np.save('b_b4',b_b4)\n",
        "np.save('c_b4',c_b4)\n",
        "np.save('cp_b4',cp_b4)\n",
        "np.save('a_b5',a_b5)\n",
        "np.save('b_b5',b_b5)\n",
        "np.save('c_b5',c_b5)\n",
        "np.save('cp_b5',cp_b5)\n",
        "np.save('a_b6',a_b6)\n",
        "np.save('b_b6',b_b6)\n",
        "np.save('c_b6',c_b6)\n",
        "np.save('cp_b6',cp_b6)\n",
        "np.save('a_b7',a_b7)\n",
        "np.save('b_b7',b_b7)\n",
        "np.save('c_b7',c_b7)\n",
        "np.save('cp_b7',cp_b7)\n",
        "np.save('a_b8',a_b8)\n",
        "np.save('b_b8',b_b8)\n",
        "np.save('c_b8',c_b8)\n",
        "np.save('cp_b8',cp_b8)\n",
        "np.save('a_b9',a_b9)\n",
        "np.save('b_b9',b_b9)\n",
        "np.save('c_b9',c_b9)\n",
        "np.save('cp_b9',cp_b9)\n",
        "\n",
        "np.save('bi1',bi1)\n",
        "np.save('bi2',bi2)\n",
        "np.save('bi3',bi3)\n",
        "np.save('bi4',bi4)\n",
        "np.save('bi5',bi5)\n",
        "np.save('bi6',bi6)\n",
        "np.save('bi7',bi7)\n",
        "np.save('bi8',bi8)\n",
        "np.save('bi9',bi9)\n",
        "np.save('fbi1',fbi1)\n",
        "np.save('fbi2',fbi2)\n",
        "np.save('fbi3',fbi3)\n",
        "np.save('fbi4',fbi4)\n",
        "np.save('fbi5',fbi5)\n",
        "np.save('fbi6',fbi6)\n",
        "np.save('fbi7',fbi7)\n",
        "np.save('fbi8',fbi8)\n",
        "np.save('fbi9',fbi9)\n",
        "\n",
        "np.save('sbi1',sbi1)\n",
        "np.save('sbi2',sbi2)\n",
        "np.save('sbi3',sbi3)\n",
        "np.save('sbi4',sbi4)\n",
        "np.save('sbi5',sbi5)\n",
        "np.save('sbi6',sbi6)\n",
        "np.save('sbi7',sbi7)\n",
        "np.save('sbi8',sbi8)\n",
        "np.save('sbi9',sbi9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "xxeIS8etmJS_",
        "outputId": "07df1b07-0614-4e11-db1b-599fc0ecf481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3f28050e50d9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a_b1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_b1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b_b1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_b1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c_b1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_b1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp_b1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcp_b1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a_b2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_b2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=np.load('a_b1.npy',allow_pickle=True)\n",
        "b_b1=np.load('b_b1.npy',allow_pickle=True)\n",
        "c_b1=np.load('c_b1.npy',allow_pickle=True)\n",
        "cp_b1=np.load('cp_b1.npy',allow_pickle=True)\n",
        "ab_b1=a_b1*b_b1\n",
        "a_b2=np.load('a_b2.npy',allow_pickle=True)\n",
        "b_b2=np.load('b_b2.npy',allow_pickle=True)\n",
        "c_b2=np.load('c_b2.npy',allow_pickle=True)\n",
        "cp_b2=np.load('cp_b2.npy',allow_pickle=True)\n",
        "ab_b2=a_b2*b_b2\n",
        "a_b3=np.load('a_b3.npy',allow_pickle=True)\n",
        "b_b3=np.load('b_b3.npy',allow_pickle=True)\n",
        "c_b3=np.load('c_b3.npy',allow_pickle=True)\n",
        "cp_b3=np.load('cp_b3.npy',allow_pickle=True)\n",
        "ab_b3=a_b3*b_b3\n",
        "a_b4=np.load('a_b4.npy',allow_pickle=True)\n",
        "b_b4=np.load('b_b4.npy',allow_pickle=True)\n",
        "c_b4=np.load('c_b4.npy',allow_pickle=True)\n",
        "cp_b4=np.load('cp_b4.npy',allow_pickle=True)\n",
        "ab_b4=a_b4*b_b4\n",
        "a_b5=np.load('a_b5.npy',allow_pickle=True)\n",
        "b_b5=np.load('b_b5.npy',allow_pickle=True)\n",
        "c_b5=np.load('c_b5.npy',allow_pickle=True)\n",
        "cp_b5=np.load('cp_b5.npy',allow_pickle=True)\n",
        "ab_b5=a_b5*b_b5\n",
        "a_b6=np.load('a_b6.npy',allow_pickle=True)\n",
        "b_b6=np.load('b_b6.npy',allow_pickle=True)\n",
        "c_b6=np.load('c_b6.npy',allow_pickle=True)\n",
        "cp_b6=np.load('cp_b6.npy',allow_pickle=True)\n",
        "ab_b6=a_b6*b_b6\n",
        "a_b7=np.load('a_b7.npy',allow_pickle=True)\n",
        "b_b7=np.load('b_b7.npy',allow_pickle=True)\n",
        "c_b7=np.load('c_b7.npy',allow_pickle=True)\n",
        "cp_b7=np.load('cp_b7.npy',allow_pickle=True)\n",
        "ab_b7=a_b7*b_b7\n",
        "a_b8=np.load('a_b8.npy',allow_pickle=True)\n",
        "b_b8=np.load('b_b8.npy',allow_pickle=True)\n",
        "c_b8=np.load('c_b8.npy',allow_pickle=True)\n",
        "cp_b8=np.load('cp_b8.npy',allow_pickle=True)\n",
        "ab_b8=a_b8*b_b8\n",
        "a_b9=np.load('a_b9.npy',allow_pickle=True)\n",
        "b_b9=np.load('b_b9.npy',allow_pickle=True)\n",
        "c_b9=np.load('c_b9.npy',allow_pickle=True)\n",
        "cp_b9=np.load('cp_b9.npy',allow_pickle=True)\n",
        "ab_b9=a_b9*b_b9\n",
        "\n",
        "bi1=np.load('bi1.npy',allow_pickle=True)\n",
        "bi2=np.load('bi2.npy',allow_pickle=True)\n",
        "bi3=np.load('bi3.npy',allow_pickle=True)\n",
        "bi4=np.load('bi4.npy',allow_pickle=True)\n",
        "bi5=np.load('bi5.npy',allow_pickle=True)\n",
        "bi6=np.load('bi6.npy',allow_pickle=True)\n",
        "bi7=np.load('bi7.npy',allow_pickle=True)\n",
        "bi8=np.load('bi8.npy',allow_pickle=True)\n",
        "bi9=np.load('bi9.npy',allow_pickle=True)\n",
        "fbi1=np.load('fbi1.npy',allow_pickle=True)\n",
        "fbi2=np.load('fbi2.npy',allow_pickle=True)\n",
        "fbi3=np.load('fbi3.npy',allow_pickle=True)\n",
        "fbi4=np.load('fbi4.npy',allow_pickle=True)\n",
        "fbi5=np.load('fbi5.npy',allow_pickle=True)\n",
        "fbi6=np.load('fbi6.npy',allow_pickle=True)\n",
        "fbi7=np.load('fbi7.npy',allow_pickle=True)\n",
        "fbi8=np.load('fbi8.npy',allow_pickle=True)\n",
        "fbi9=np.load('fbi9.npy',allow_pickle=True)"
      ],
      "metadata": {
        "id": "RU4e2QP5mJZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1= a_b1.tolist()\n",
        "b_b1= b_b1.tolist()\n",
        "c_b1= c_b1.tolist()\n",
        "cp_b1= cp_b1.tolist()\n",
        "ab_b1= ab_b1.tolist()\n",
        "a_b2= a_b2.tolist()\n",
        "b_b2= b_b2.tolist()\n",
        "c_b2= c_b2.tolist()\n",
        "cp_b2= cp_b2.tolist()\n",
        "ab_b2= ab_b2.tolist()\n",
        "a_b3= a_b3.tolist()\n",
        "b_b3= b_b3.tolist()\n",
        "c_b3= c_b3.tolist()\n",
        "cp_b3= cp_b3.tolist()\n",
        "ab_b3= ab_b3.tolist()\n",
        "a_b4= a_b4.tolist()\n",
        "b_b4= b_b4.tolist()\n",
        "c_b4= c_b4.tolist()\n",
        "cp_b4= cp_b4.tolist()\n",
        "ab_b4= ab_b4.tolist()\n",
        "a_b5= a_b5.tolist()\n",
        "b_b5= b_b5.tolist()\n",
        "c_b5= c_b5.tolist()\n",
        "cp_b5= cp_b5.tolist()\n",
        "ab_b5= ab_b5.tolist()\n",
        "a_b6= a_b6.tolist()\n",
        "b_b6= b_b6.tolist()\n",
        "c_b6= c_b6.tolist()\n",
        "cp_b6= cp_b6.tolist()\n",
        "ab_b6= ab_b6.tolist()\n",
        "a_b7= a_b7.tolist()\n",
        "b_b7= b_b7.tolist()\n",
        "c_b7= c_b7.tolist()\n",
        "cp_b7= cp_b7.tolist()\n",
        "ab_b7= ab_b7.tolist()\n",
        "a_b8= a_b8.tolist()\n",
        "b_b8= b_b8.tolist()\n",
        "c_b8= c_b8.tolist()\n",
        "cp_b8= cp_b8.tolist()\n",
        "ab_b8= ab_b8.tolist()\n",
        "a_b9= a_b9.tolist()\n",
        "b_b9= b_b9.tolist()\n",
        "c_b9= c_b9.tolist()\n",
        "cp_b9= cp_b9.tolist()\n",
        "ab_b9= ab_b9.tolist()\n",
        "\n",
        "bi1=bi1.tolist()\n",
        "bi2=bi2.tolist()\n",
        "bi3=bi3.tolist()\n",
        "bi4=bi4.tolist()\n",
        "bi5=bi5.tolist()\n",
        "bi6=bi6.tolist()\n",
        "bi7=bi7.tolist()\n",
        "bi8=bi8.tolist()\n",
        "bi9=bi9.tolist()\n",
        "\n",
        "fbi1=fbi1.tolist()\n",
        "fbi2=fbi2.tolist()\n",
        "fbi3=fbi3.tolist()\n",
        "fbi4=fbi4.tolist()\n",
        "fbi5=fbi5.tolist()\n",
        "fbi6=fbi6.tolist()\n",
        "fbi7=fbi7.tolist()\n",
        "fbi8=fbi8.tolist()\n",
        "fbi9=fbi9.tolist()"
      ],
      "metadata": {
        "id": "dHirDpP6thcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=np.array(a_b1)\n",
        "b_b1=np.array(b_b1)\n",
        "c_b1=np.array(c_b1)\n",
        "cp_b1=np.array(cp_b1)\n",
        "ab_b1=np.array(ab_b1)\n",
        "a_b2=np.array(a_b2)\n",
        "b_b2=np.array(b_b2)\n",
        "c_b2=np.array(c_b2)\n",
        "cp_b2=np.array(cp_b2)\n",
        "ab_b2=np.array(ab_b2)\n",
        "a_b3=np.array(a_b3)\n",
        "b_b3=np.array(b_b3)\n",
        "c_b3=np.array(c_b3)\n",
        "cp_b3=np.array(cp_b3)\n",
        "ab_b3=np.array(ab_b3)\n",
        "a_b4=np.array(a_b4)\n",
        "b_b4=np.array(b_b4)\n",
        "c_b4=np.array(c_b4)\n",
        "cp_b4=np.array(cp_b4)\n",
        "ab_b4=np.array(ab_b4)\n",
        "a_b5=np.array(a_b5)\n",
        "b_b5=np.array(b_b5)\n",
        "c_b5=np.array(c_b5)\n",
        "cp_b5=np.array(cp_b5)\n",
        "ab_b5=np.array(ab_b5)\n",
        "a_b6=np.array(a_b6)\n",
        "b_b6=np.array(b_b6)\n",
        "c_b6=np.array(c_b6)\n",
        "cp_b6=np.array(cp_b6)\n",
        "ab_b6=np.array(ab_b6)\n",
        "a_b7=np.array(a_b7)\n",
        "b_b7=np.array(b_b7)\n",
        "c_b7=np.array(c_b7)\n",
        "cp_b7=np.array(cp_b7)\n",
        "ab_b7=np.array(ab_b7)\n",
        "a_b8=np.array(a_b8)\n",
        "b_b8=np.array(b_b8)\n",
        "c_b8=np.array(c_b8)\n",
        "cp_b8=np.array(cp_b8)\n",
        "ab_b8=np.array(ab_b8)\n",
        "a_b9=np.array(a_b9)\n",
        "b_b9=np.array(b_b9)\n",
        "c_b9=np.array(c_b9)\n",
        "cp_b9=np.array(cp_b9)\n",
        "ab_b9=np.array(ab_b9)\n",
        "\n",
        "bi1=np.array(bi1)\n",
        "bi2=np.array(bi2)\n",
        "bi3=np.array(bi3)\n",
        "bi4=np.array(bi4)\n",
        "bi5=np.array(bi5)\n",
        "bi6=np.array(bi6)\n",
        "bi7=np.array(bi7)\n",
        "bi8=np.array(bi8)\n",
        "bi9=np.array(bi9)\n",
        "\n",
        "fbi1=np.array(fbi1)\n",
        "fbi2=np.array(fbi2)\n",
        "fbi3=np.array(fbi3)\n",
        "fbi4=np.array(fbi4)\n",
        "fbi5=np.array(fbi5)\n",
        "fbi6=np.array(fbi6)\n",
        "fbi7=np.array(fbi7)\n",
        "fbi8=np.array(fbi8)\n",
        "fbi9=np.array(fbi9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdAVilXtdwyc",
        "outputId": "bc314932-080d-4d6c-dc52-e617b4fe9f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-c0b9cb1af28d>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b1=np.array(a_b1)\n",
            "<ipython-input-8-c0b9cb1af28d>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b1=np.array(a_b1)\n",
            "<ipython-input-8-c0b9cb1af28d>:4: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b1=np.array(cp_b1)\n",
            "<ipython-input-8-c0b9cb1af28d>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b1=np.array(cp_b1)\n",
            "<ipython-input-8-c0b9cb1af28d>:5: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b1=np.array(ab_b1)\n",
            "<ipython-input-8-c0b9cb1af28d>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b1=np.array(ab_b1)\n",
            "<ipython-input-8-c0b9cb1af28d>:6: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b2=np.array(a_b2)\n",
            "<ipython-input-8-c0b9cb1af28d>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b2=np.array(a_b2)\n",
            "<ipython-input-8-c0b9cb1af28d>:9: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b2=np.array(cp_b2)\n",
            "<ipython-input-8-c0b9cb1af28d>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b2=np.array(cp_b2)\n",
            "<ipython-input-8-c0b9cb1af28d>:10: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b2=np.array(ab_b2)\n",
            "<ipython-input-8-c0b9cb1af28d>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b2=np.array(ab_b2)\n",
            "<ipython-input-8-c0b9cb1af28d>:11: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b3=np.array(a_b3)\n",
            "<ipython-input-8-c0b9cb1af28d>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b3=np.array(a_b3)\n",
            "<ipython-input-8-c0b9cb1af28d>:14: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b3=np.array(cp_b3)\n",
            "<ipython-input-8-c0b9cb1af28d>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b3=np.array(cp_b3)\n",
            "<ipython-input-8-c0b9cb1af28d>:15: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b3=np.array(ab_b3)\n",
            "<ipython-input-8-c0b9cb1af28d>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b3=np.array(ab_b3)\n",
            "<ipython-input-8-c0b9cb1af28d>:16: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b4=np.array(a_b4)\n",
            "<ipython-input-8-c0b9cb1af28d>:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b4=np.array(a_b4)\n",
            "<ipython-input-8-c0b9cb1af28d>:19: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b4=np.array(cp_b4)\n",
            "<ipython-input-8-c0b9cb1af28d>:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b4=np.array(cp_b4)\n",
            "<ipython-input-8-c0b9cb1af28d>:20: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b4=np.array(ab_b4)\n",
            "<ipython-input-8-c0b9cb1af28d>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b4=np.array(ab_b4)\n",
            "<ipython-input-8-c0b9cb1af28d>:21: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b5=np.array(a_b5)\n",
            "<ipython-input-8-c0b9cb1af28d>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b5=np.array(a_b5)\n",
            "<ipython-input-8-c0b9cb1af28d>:24: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b5=np.array(cp_b5)\n",
            "<ipython-input-8-c0b9cb1af28d>:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b5=np.array(cp_b5)\n",
            "<ipython-input-8-c0b9cb1af28d>:25: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b5=np.array(ab_b5)\n",
            "<ipython-input-8-c0b9cb1af28d>:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b5=np.array(ab_b5)\n",
            "<ipython-input-8-c0b9cb1af28d>:26: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b6=np.array(a_b6)\n",
            "<ipython-input-8-c0b9cb1af28d>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b6=np.array(a_b6)\n",
            "<ipython-input-8-c0b9cb1af28d>:29: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b6=np.array(cp_b6)\n",
            "<ipython-input-8-c0b9cb1af28d>:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b6=np.array(cp_b6)\n",
            "<ipython-input-8-c0b9cb1af28d>:30: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b6=np.array(ab_b6)\n",
            "<ipython-input-8-c0b9cb1af28d>:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b6=np.array(ab_b6)\n",
            "<ipython-input-8-c0b9cb1af28d>:31: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b7=np.array(a_b7)\n",
            "<ipython-input-8-c0b9cb1af28d>:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b7=np.array(a_b7)\n",
            "<ipython-input-8-c0b9cb1af28d>:34: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b7=np.array(cp_b7)\n",
            "<ipython-input-8-c0b9cb1af28d>:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b7=np.array(cp_b7)\n",
            "<ipython-input-8-c0b9cb1af28d>:35: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b7=np.array(ab_b7)\n",
            "<ipython-input-8-c0b9cb1af28d>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b7=np.array(ab_b7)\n",
            "<ipython-input-8-c0b9cb1af28d>:36: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b8=np.array(a_b8)\n",
            "<ipython-input-8-c0b9cb1af28d>:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b8=np.array(a_b8)\n",
            "<ipython-input-8-c0b9cb1af28d>:39: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b8=np.array(cp_b8)\n",
            "<ipython-input-8-c0b9cb1af28d>:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b8=np.array(cp_b8)\n",
            "<ipython-input-8-c0b9cb1af28d>:40: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b8=np.array(ab_b8)\n",
            "<ipython-input-8-c0b9cb1af28d>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b8=np.array(ab_b8)\n",
            "<ipython-input-8-c0b9cb1af28d>:41: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b9=np.array(a_b9)\n",
            "<ipython-input-8-c0b9cb1af28d>:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b9=np.array(a_b9)\n",
            "<ipython-input-8-c0b9cb1af28d>:44: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b9=np.array(cp_b9)\n",
            "<ipython-input-8-c0b9cb1af28d>:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b9=np.array(cp_b9)\n",
            "<ipython-input-8-c0b9cb1af28d>:45: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b9=np.array(ab_b9)\n",
            "<ipython-input-8-c0b9cb1af28d>:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b9=np.array(ab_b9)\n",
            "<ipython-input-8-c0b9cb1af28d>:47: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi1=np.array(bi1)\n",
            "<ipython-input-8-c0b9cb1af28d>:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi1=np.array(bi1)\n",
            "<ipython-input-8-c0b9cb1af28d>:48: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi2=np.array(bi2)\n",
            "<ipython-input-8-c0b9cb1af28d>:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi2=np.array(bi2)\n",
            "<ipython-input-8-c0b9cb1af28d>:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi3=np.array(bi3)\n",
            "<ipython-input-8-c0b9cb1af28d>:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi3=np.array(bi3)\n",
            "<ipython-input-8-c0b9cb1af28d>:50: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi4=np.array(bi4)\n",
            "<ipython-input-8-c0b9cb1af28d>:50: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi4=np.array(bi4)\n",
            "<ipython-input-8-c0b9cb1af28d>:51: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi5=np.array(bi5)\n",
            "<ipython-input-8-c0b9cb1af28d>:51: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi5=np.array(bi5)\n",
            "<ipython-input-8-c0b9cb1af28d>:52: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi6=np.array(bi6)\n",
            "<ipython-input-8-c0b9cb1af28d>:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi6=np.array(bi6)\n",
            "<ipython-input-8-c0b9cb1af28d>:53: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi7=np.array(bi7)\n",
            "<ipython-input-8-c0b9cb1af28d>:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi7=np.array(bi7)\n",
            "<ipython-input-8-c0b9cb1af28d>:54: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi8=np.array(bi8)\n",
            "<ipython-input-8-c0b9cb1af28d>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi8=np.array(bi8)\n",
            "<ipython-input-8-c0b9cb1af28d>:55: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi9=np.array(bi9)\n",
            "<ipython-input-8-c0b9cb1af28d>:55: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi9=np.array(bi9)\n",
            "<ipython-input-8-c0b9cb1af28d>:57: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi1=np.array(fbi1)\n",
            "<ipython-input-8-c0b9cb1af28d>:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi1=np.array(fbi1)\n",
            "<ipython-input-8-c0b9cb1af28d>:58: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi2=np.array(fbi2)\n",
            "<ipython-input-8-c0b9cb1af28d>:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi2=np.array(fbi2)\n",
            "<ipython-input-8-c0b9cb1af28d>:59: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi3=np.array(fbi3)\n",
            "<ipython-input-8-c0b9cb1af28d>:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi3=np.array(fbi3)\n",
            "<ipython-input-8-c0b9cb1af28d>:60: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi4=np.array(fbi4)\n",
            "<ipython-input-8-c0b9cb1af28d>:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi4=np.array(fbi4)\n",
            "<ipython-input-8-c0b9cb1af28d>:61: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi5=np.array(fbi5)\n",
            "<ipython-input-8-c0b9cb1af28d>:61: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi5=np.array(fbi5)\n",
            "<ipython-input-8-c0b9cb1af28d>:62: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi6=np.array(fbi6)\n",
            "<ipython-input-8-c0b9cb1af28d>:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi6=np.array(fbi6)\n",
            "<ipython-input-8-c0b9cb1af28d>:63: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi7=np.array(fbi7)\n",
            "<ipython-input-8-c0b9cb1af28d>:63: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi7=np.array(fbi7)\n",
            "<ipython-input-8-c0b9cb1af28d>:64: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi8=np.array(fbi8)\n",
            "<ipython-input-8-c0b9cb1af28d>:64: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi8=np.array(fbi8)\n",
            "<ipython-input-8-c0b9cb1af28d>:65: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi9=np.array(fbi9)\n",
            "<ipython-input-8-c0b9cb1af28d>:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi9=np.array(fbi9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_1=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_1[i]=bi1[i].item()\n",
        "bi_2=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_2[i]=bi2[i].item()\n",
        "bi_3=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_3[i]=bi3[i].item()\n",
        "bi_4=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_4[i]=bi4[i].item()\n",
        "bi_5=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_5[i]=bi5[i].item()\n",
        "bi_6=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_6[i]=bi6[i].item()\n",
        "bi_7=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_7[i]=bi7[i].item()\n",
        "bi_8=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_8[i]=bi8[i].item()\n",
        "bi_9=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_9[i]=bi9[i].item()\n"
      ],
      "metadata": {
        "id": "u1AWzSmPk1ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "statistics.mean(bi_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w85XrH-pI2d",
        "outputId": "d8ca866a-d97a-47b5-96ff-5fc940b5c345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006754265789873898"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fbi1=np.asarray(fbi1,dtype=np.float64)\n",
        "fbi2=np.asarray(fbi2,dtype=np.float64)\n",
        "fbi3=np.asarray(fbi3,dtype=np.float64)\n",
        "fbi4=np.asarray(fbi4,dtype=np.float64)\n",
        "fbi5=np.asarray(fbi5,dtype=np.float64)\n",
        "fbi6=np.asarray(fbi6,dtype=np.float64)\n",
        "fbi7=np.asarray(fbi7,dtype=np.float64)\n",
        "fbi8=np.asarray(fbi8,dtype=np.float64)\n",
        "fbi9=np.asarray(fbi9,dtype=np.float64)\n",
        "a1=np.asarray(a_b1,dtype=np.float64)\n",
        "a2=np.asarray(a_b2,dtype=np.float64)\n",
        "a3=np.asarray(a_b3,dtype=np.float64)\n",
        "a4=np.asarray(a_b4,dtype=np.float64)\n",
        "a5=np.asarray(a_b5,dtype=np.float64)\n",
        "a6=np.asarray(a_b6,dtype=np.float64)\n",
        "a7=np.asarray(a_b7,dtype=np.float64)\n",
        "a8=np.asarray(a_b8,dtype=np.float64)\n",
        "a9=np.asarray(a_b9,dtype=np.float64)"
      ],
      "metadata": {
        "id": "XL-IM3ETP-4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=[None]*9\n",
        "b=[None]*9\n",
        "bi=[None]*9\n",
        "a=[None]*9\n",
        "fbi=[None]*9\n",
        "c[0]=c_b1.mean()\n",
        "b[0]=b_b1.mean()\n",
        "bi[0]=statistics.mean(bi_1)\n",
        "c[1]=c_b2.mean()\n",
        "b[1]=b_b2.mean()\n",
        "bi[1]=statistics.mean(bi_2)\n",
        "c[2]=c_b3.mean()\n",
        "b[2]=b_b3.mean()\n",
        "bi[2]=statistics.mean(bi_3)\n",
        "c[3]=c_b4.mean()\n",
        "b[3]=b_b4.mean()\n",
        "bi[3]=statistics.mean(bi_4)\n",
        "c[4]=c_b5.mean()\n",
        "b[4]=b_b5.mean()\n",
        "bi[4]=statistics.mean(bi_5)\n",
        "c[5]=c_b6.mean()\n",
        "b[5]=b_b6.mean()\n",
        "bi[5]=statistics.mean(bi_6)\n",
        "c[6]=c_b7.mean()\n",
        "b[6]=b_b7.mean()\n",
        "bi[6]=statistics.mean(bi_7)\n",
        "c[7]=c_b8.mean()\n",
        "b[7]=b_b8.mean()\n",
        "bi[7]=statistics.mean(bi_8)\n",
        "c[8]=c_b9.mean()\n",
        "b[8]=b_b9.mean()\n",
        "bi[8]=statistics.mean(bi_9)\n",
        "a[0]=a1.mean()\n",
        "a[1]=a2.mean()\n",
        "a[2]=a3.mean()\n",
        "a[3]=a4.mean()\n",
        "a[4]=a5.mean()\n",
        "a[5]=a6.mean()\n",
        "a[6]=a7.mean()\n",
        "a[7]=a8.mean()\n",
        "a[8]=a9.mean()\n",
        "fbi[0]=fbi1.mean()\n",
        "fbi[1]=fbi2.mean()\n",
        "fbi[2]=fbi3.mean()\n",
        "fbi[3]=fbi4.mean()\n",
        "fbi[4]=fbi5.mean()\n",
        "fbi[5]=fbi6.mean()\n",
        "fbi[6]=fbi7.mean()\n",
        "fbi[7]=fbi8.mean()\n",
        "fbi[8]=fbi9.mean()"
      ],
      "metadata": {
        "id": "ovErcRjVfDH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bi[8],c[8],b[8],fbi[8],a[8])\n",
        "m1= fbi[0] + a[0]*x\n",
        "m2= fbi[1] + a[1]*x\n",
        "m3= fbi[2] + a[2]*x\n",
        "m4= fbi[3] + a[3]*x\n",
        "m5= fbi[4] + a[4]*x\n",
        "m6= fbi[5] + a[5]*x\n",
        "m7= fbi[6] + a[6]*x\n",
        "m8= fbi[7] + a[7]*x\n",
        "m9= fbi[8] + a[8]*x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO-mxk0WQD2b",
        "outputId": "e70fe677-45c5-49c2-8b5f-74e3b5b12ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2474836140871048 0.18222293159663677 -0.12545186276584863 0.6127349110245704 0.004906721536549594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_h1=bi[0]+c[0]*x+b[0]*m1\n",
        "y_h2=bi[1]+c[1]*x+b[1]*m2\n",
        "y_h3=bi[2]+c[2]*x+b[2]*m3\n",
        "y_h4=bi[3]+c[3]*x+b[3]*m4\n",
        "y_h5=bi[4]+c[4]*x+b[4]*m5\n",
        "y_h6=bi[5]+c[5]*x+b[5]*m6\n",
        "y_h7=bi[6]+c[6]*x+b[6]*m7\n",
        "y_h8=bi[7]+c[7]*x+b[7]*m8\n",
        "y_h9=bi[8]+c[8]*x+b[8]*m9"
      ],
      "metadata": {
        "id": "DVj7dGr7lq2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TSS = ((y-y.mean())**2).sum(axis=1).sum()\n",
        "SSR1 = ((y_h1-y.mean())**2).sum(axis=1).sum()\n",
        "SSE1 = ((y-y_h1)**2).sum(axis=1).sum()\n",
        "SSR2 = ((y_h2-y.mean())**2).sum(axis=1).sum()\n",
        "SSE2 = ((y-y_h2)**2).sum(axis=1).sum()\n",
        "SSR3 = ((y_h3-y.mean())**2).sum(axis=1).sum()\n",
        "SSE3 = ((y-y_h3)**2).sum(axis=1).sum()\n",
        "SSR4 = ((y_h4-y.mean())**2).sum(axis=1).sum()\n",
        "SSE4 = ((y-y_h4)**2).sum(axis=1).sum()\n",
        "SSR5 = ((y_h5-y.mean())**2).sum(axis=1).sum()\n",
        "SSE5 = ((y-y_h5)**2).sum(axis=1).sum()\n",
        "SSR6 = ((y_h6-y.mean())**2).sum(axis=1).sum()\n",
        "SSE6 = ((y-y_h6)**2).sum(axis=1).sum()\n",
        "SSR7 = ((y_h7-y.mean())**2).sum(axis=1).sum()\n",
        "SSE7 = ((y-y_h7)**2).sum(axis=1).sum()\n",
        "SSR8 = ((y_h8-y.mean())**2).sum(axis=1).sum()\n",
        "SSE8 = ((y-y_h8)**2).sum(axis=1).sum()\n",
        "SSR9 = ((y_h9-y.mean())**2).sum(axis=1).sum()\n",
        "SSE9 = ((y-y_h9)**2).sum(axis=1).sum()\n"
      ],
      "metadata": {
        "id": "6EuMdD-br6Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE1 = np.sqrt(((y-y_h1)**2).sum(axis=1).sum()/60)\n",
        "MSE2 = np.sqrt(((y-y_h2)**2).sum(axis=1).sum()/60)\n",
        "MSE3 = np.sqrt(((y-y_h3)**2).sum(axis=1).sum()/60)\n",
        "MSE4 = np.sqrt(((y-y_h4)**2).sum(axis=1).sum()/60)\n",
        "MSE5 = np.sqrt(((y-y_h5)**2).sum(axis=1).sum()/60)\n",
        "MSE6 = np.sqrt(((y-y_h6)**2).sum(axis=1).sum()/60)\n",
        "MSE7 = np.sqrt(((y-y_h7)**2).sum(axis=1).sum()/60)\n",
        "MSE8 = np.sqrt(((y-y_h8)**2).sum(axis=1).sum()/60)\n",
        "MSE9 = np.sqrt(((y-y_h9)**2).sum(axis=1).sum()/60)\n"
      ],
      "metadata": {
        "id": "_YkdrHzGmTZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(MSE1)\n",
        "print(MSE2)\n",
        "print(MSE3)\n",
        "print(MSE4)\n",
        "print(MSE5)\n",
        "print(MSE6)\n",
        "print(MSE7)\n",
        "print(MSE8)\n",
        "print(MSE9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P62AaWY2oZms",
        "outputId": "7fa5d1f4-9e07-4f53-840c-0284afc6e559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9023992935204405\n",
            "0.9106831789451039\n",
            "0.9215203825409725\n",
            "0.9329521785310676\n",
            "0.9432929679404828\n",
            "0.9519270731281835\n",
            "0.9587551485272755\n",
            "0.9639041423314784\n",
            "0.9675879597571324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSA1 = np.abs(y-y_h1).sum(axis=1).sum()/60\n",
        "MSA2 = np.abs(y-y_h2).sum(axis=1).sum()/60\n",
        "MSA3 = np.abs(y-y_h3).sum(axis=1).sum()/60\n",
        "MSA4 = np.abs(y-y_h4).sum(axis=1).sum()/60\n",
        "MSA5 = np.abs(y-y_h5).sum(axis=1).sum()/60\n",
        "MSA6 = np.abs(y-y_h6).sum(axis=1).sum()/60\n",
        "MSA7 = np.abs(y-y_h7).sum(axis=1).sum()/60\n",
        "MSA8 = np.abs(y-y_h8).sum(axis=1).sum()/60\n",
        "MSA9 = np.abs(y-y_h9).sum(axis=1).sum()/60"
      ],
      "metadata": {
        "id": "cYpo6PzEixUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(MSA1)\n",
        "print(MSA2)\n",
        "print(MSA3)\n",
        "print(MSA4)\n",
        "print(MSA5)\n",
        "print(MSA6)\n",
        "print(MSA7)\n",
        "print(MSA8)\n",
        "print(MSA9)"
      ],
      "metadata": {
        "id": "JzKABSaLizFX",
        "outputId": "8b41ec68-9532-4e9c-bc4d-86816c20c204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1925827747158102\n",
            "1.2080804459041898\n",
            "1.2233853803847345\n",
            "1.2375827715249952\n",
            "1.2507123090910768\n",
            "1.2613479477570768\n",
            "1.2694834606257872\n",
            "1.2753996943568124\n",
            "1.2792293325057809\n"
          ]
        }
      ]
    }
  ]
}