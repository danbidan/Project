{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOCYH-4yNMMr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from scipy import stats\n",
        "from scipy.stats import t, f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import skew, kurtosis"
      ],
      "metadata": {
        "id": "DtxMO3VJNVF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "random_seed = 2\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)"
      ],
      "metadata": {
        "id": "Uf2gsadbNVLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"solar.txt\")\n",
        "data.head\n",
        "data=data.rename(columns={'cloud cover':'sky_cover'})\n",
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H1244zTNVSP",
        "outputId": "737d39f5-6865-4b2b-ac42-c869fd910be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1332"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te=data['temp']\n",
        "spreadx= [None] * 1332\n",
        "for i in range(0,1331):\n",
        "  spreadx[i]= (np.abs(te[i+1]-te[i]))/2\n",
        "spreadx[1331]=spreadx[1330]"
      ],
      "metadata": {
        "id": "VmvAuTPWPWfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hu=data['humidity']\n",
        "spreadm= [None] * 1332\n",
        "for i in range(0,1331):\n",
        "  spreadm[i]= (np.abs(hu[i+1]-hu[i]))/2\n",
        "spreadm[1331]=spreadm[1330]"
      ],
      "metadata": {
        "id": "hMSnEKSAPXAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " te=data['temp']\n",
        " spread= [None] * 1332\n",
        " for i in range(0,1332):\n",
        "    spread[i]= spreadx[te.index[i]]\n",
        " x1= te-spread\n",
        " x2= te+spread\n",
        " xdf=pd.DataFrame({'a':x1,'b':te,'c':x2})\n",
        " xa=xdf[xdf['a']< 0]\n",
        " xdf.loc[xa.index,'a']=0\n",
        " x=xdf.to_numpy()\n",
        "\n",
        " hu=data['humidity']\n",
        " spreadm2= [None] * 1332\n",
        " for i in range(0,1332):\n",
        "  spreadm2[i]= spreadm[hu.index[i]]\n",
        " m1= hu-spreadm2\n",
        " m2= hu+spreadm2\n",
        " mdf=pd.DataFrame({'a':m1,'b':hu,'c':m2})\n",
        " ma=mdf[mdf['a']< 0]\n",
        " mdf.loc[ma.index,'a']=0\n",
        " m=mdf.to_numpy()\n",
        "\n",
        " power=data['day_power']\n",
        " ydf=pd.DataFrame({'a':power,'b':power,'c':power})\n",
        " y= ydf.to_numpy()\n",
        "\n",
        " cl=data['sky_cover']\n",
        " w1= cl-1\n",
        " w2= cl+1\n",
        " wdf=pd.DataFrame({'a':w1,'b':cl,'c':w2})\n",
        " wa=wdf[wdf['a']< 1]\n",
        " wdf.loc[wa.index,'a']=1\n",
        " wc=wdf[wdf['c']> 8]\n",
        " wdf.loc[wc.index,'c']=8\n",
        " w_v=wdf.to_numpy()\n",
        " xw_v=x*w_v"
      ],
      "metadata": {
        "id": "WqwnGWvVPXPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HqyEiIZF14f"
      },
      "outputs": [],
      "source": [
        "def gpbdl1(data):\n",
        " te=data['temp']\n",
        " spread= [None] * 1332\n",
        " for i in range(0,1332):\n",
        "    spread[i]= spreadx[te.index[i]]\n",
        " x1= te-spread\n",
        " x2= te+spread\n",
        " xdf=pd.DataFrame({'a':x1,'b':te,'c':x2})\n",
        " xa=xdf[xdf['a']< 0]\n",
        " xdf.loc[xa.index,'a']=0\n",
        " x=xdf.to_numpy()\n",
        "\n",
        " hu=data['humidity']\n",
        " spreadm2= [None] * 1332\n",
        " for i in range(0,1332):\n",
        "  spreadm2[i]= spreadm[hu.index[i]]\n",
        " m1= hu-spreadm2\n",
        " m2= hu+spreadm2\n",
        " mdf=pd.DataFrame({'a':m1,'b':hu,'c':m2})\n",
        " ma=mdf[mdf['a']< 0]\n",
        " mdf.loc[ma.index,'a']=0\n",
        " m=mdf.to_numpy()\n",
        "\n",
        " power=data['day_power']\n",
        " ydf=pd.DataFrame({'a':power,'b':power,'c':power})\n",
        " y= ydf.to_numpy()\n",
        "\n",
        " cl=data['sky_cover']\n",
        " w1= cl-1\n",
        " w2= cl+1\n",
        " wdf=pd.DataFrame({'a':w1,'b':cl,'c':w2})\n",
        " wa=wdf[wdf['a']< 1]\n",
        " wdf.loc[wa.index,'a']=1\n",
        " wc=wdf[wdf['c']> 8]\n",
        " wdf.loc[wc.index,'c']=8\n",
        " w=wdf.to_numpy()\n",
        " xw=x*w\n",
        "\n",
        " X_l = []\n",
        " X_m = []\n",
        " X_r = []\n",
        "\n",
        " M_l = []\n",
        " M_m = []\n",
        " M_r = []\n",
        "\n",
        " Y_l = []\n",
        " Y_m = []\n",
        " Y_r = []\n",
        "\n",
        " W_l = []\n",
        " W_m = []\n",
        " W_r = []\n",
        "\n",
        " XW_l = []\n",
        " XW_m = []\n",
        " XW_r = []\n",
        " for i in range(len(data)):\n",
        "    X_l.append(x[i][0])\n",
        "    X_m.append(x[i][1])\n",
        "    X_r.append(x[i][2])\n",
        " for i in range(len(data)):\n",
        "    M_l.append(m[i][0])\n",
        "    M_m.append(m[i][1])\n",
        "    M_r.append(m[i][2])\n",
        "\n",
        " for i in range(len(data)):\n",
        "    Y_l.append(y[i][0])\n",
        "    Y_m.append(y[i][1])\n",
        "    Y_r.append(y[i][2])\n",
        "\n",
        " for i in range(len(data)):\n",
        "    W_l.append(w[i][0])\n",
        "    W_m.append(w[i][1])\n",
        "    W_r.append(w[i][2])\n",
        "\n",
        " for i in range(len(data)):\n",
        "    XW_l.append(xw[i][0])\n",
        "    XW_m.append(xw[i][1])\n",
        "    XW_r.append(xw[i][2])\n",
        "\n",
        " ep = 800\n",
        " x_train = torch.FloatTensor([X_l])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([M_l])\n",
        " y_train = y_train.T\n",
        " Weight_l = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_l = torch.zeros(1, requires_grad=True)\n",
        " w_l=torch.zeros((9,1))\n",
        " b_l=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i]= Weight_l\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        "\n",
        " x_train = torch.FloatTensor([X_m])\n",
        " x_train = x_train.T\n",
        " x_train.shape\n",
        " y_train = torch.FloatTensor([M_m]) # M\n",
        " y_train = y_train.T\n",
        " Weight_m = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_m = torch.zeros(1, requires_grad=True)\n",
        " w_m=torch.zeros((9,1))\n",
        " b_m=torch.zeros((9,1))\n",
        " i=0\n",
        " optimizer = optim.Adagrad([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i]= Weight_m\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        " x_train = torch.FloatTensor([X_r])\n",
        " x_train = x_train.T\n",
        " x_train.shape\n",
        " y_train = torch.FloatTensor([M_r]) # M\n",
        " y_train = y_train.T\n",
        " Weight_r = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_r = torch.zeros(1, requires_grad=True)\n",
        " w_r=torch.zeros((9,1))\n",
        " b_r=torch.zeros((9,1))\n",
        " i=0\n",
        " optimizer = optim.Adagrad([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_r[i]= Weight_r\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        " w1=(w_l + w_m + w_r)/ 3\n",
        " b1=(b_l + b_m + b_r)/ 3\n",
        "\n",
        " x_train = torch.FloatTensor([X_l,W_l,XW_l,M_l])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([Y_l])\n",
        " y_train = y_train.T\n",
        " Weight_l = torch.zeros((4,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_l = torch.zeros(1, requires_grad=True)\n",
        " w_l=torch.zeros((9,4))\n",
        " b_l=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i][0]= Weight_l[0]\n",
        "      w_l[i][1]= Weight_l[1]\n",
        "      w_l[i][2]= Weight_l[2]\n",
        "      w_l[i][3]= Weight_l[3]\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        " x_train = torch.FloatTensor([X_m,W_m,XW_m,M_m])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([Y_m])\n",
        " y_train = y_train.T\n",
        " Weight_m = torch.zeros((4,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_m = torch.zeros(1, requires_grad=True)\n",
        " w_m=torch.zeros((9,4))\n",
        " b_m=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i][0]= Weight_m[0]\n",
        "      w_m[i][1]= Weight_m[1]\n",
        "      w_m[i][2]= Weight_m[2]\n",
        "      w_m[i][3]= Weight_m[3]\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        " x_train = torch.FloatTensor([X_r,W_r,XW_r,M_r])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([Y_r])\n",
        " y_train = y_train.T\n",
        " Weight_r = torch.zeros((4,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_r = torch.zeros(1, requires_grad=True)\n",
        " w_r=torch.zeros((9,4))\n",
        " b_r=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_r[i][0]= Weight_r[0]\n",
        "      w_r[i][1]= Weight_r[1]\n",
        "      w_r[i][2]= Weight_r[2]\n",
        "      w_r[i][3]= Weight_r[3]\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        "\n",
        " w2=(w_l + w_m + w_r)/ 3\n",
        " b2=(b_l + b_m + b_r)/ 3\n",
        "\n",
        " x_train = torch.FloatTensor([X_l])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([Y_l])\n",
        " y_train = y_train.T\n",
        " Weight_l = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_l = torch.zeros(1, requires_grad=True)\n",
        " w_l=torch.zeros((9,1))\n",
        " b_l=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i]= Weight_l\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        "\n",
        " x_train = torch.FloatTensor([X_m])\n",
        " x_train = x_train.T\n",
        " x_train.shape\n",
        " y_train = torch.FloatTensor([Y_m])\n",
        " y_train = y_train.T\n",
        " Weight_m = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_m = torch.zeros(1, requires_grad=True)\n",
        " w_m=torch.zeros((9,1))\n",
        " b_m=torch.zeros((9,1))\n",
        " i=0\n",
        " optimizer = optim.Adagrad([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i]= Weight_m\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        " x_train = torch.FloatTensor([X_r])\n",
        " x_train = x_train.T\n",
        " x_train.shape\n",
        " y_train = torch.FloatTensor([Y_r])\n",
        " y_train = y_train.T\n",
        " Weight_r = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_r = torch.zeros(1, requires_grad=True)\n",
        " w_r=torch.zeros((9,1))\n",
        " b_r=torch.zeros((9,1))\n",
        " i=0\n",
        " optimizer = optim.Adagrad([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_r[i]= Weight_r\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        " w3=(w_l + w_m + w_r)/ 3\n",
        " b3=(b_l + b_m + b_r)/ 3\n",
        " return w1,b1,w2,b2,w3,b3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "av=gpbdl1(data)\n",
        "av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWmC8nLmSMlT",
        "outputId": "dd5e8135-29be-4627-c71b-42e61c12083c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0100],\n",
              "         [0.1669],\n",
              "         [0.2257],\n",
              "         [0.2633],\n",
              "         [0.2892],\n",
              "         [0.3076],\n",
              "         [0.3205],\n",
              "         [0.3292],\n",
              "         [0.3349]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0100],\n",
              "         [0.1693],\n",
              "         [0.2314],\n",
              "         [0.2731],\n",
              "         [0.3040],\n",
              "         [0.3279],\n",
              "         [0.3469],\n",
              "         [0.3623],\n",
              "         [0.3751]], grad_fn=<DivBackward0>),\n",
              " tensor([[ 0.0100,  0.0100,  0.0100,  0.0100],\n",
              "         [ 0.1027,  0.0143,  0.0763, -0.0155],\n",
              "         [ 0.1463, -0.0031,  0.1001, -0.0547],\n",
              "         [ 0.1775, -0.0151,  0.1143, -0.0847],\n",
              "         [ 0.2012, -0.0235,  0.1225, -0.1094],\n",
              "         [ 0.2200, -0.0294,  0.1268, -0.1309],\n",
              "         [ 0.2354, -0.0335,  0.1286, -0.1504],\n",
              "         [ 0.2483, -0.0364,  0.1286, -0.1686],\n",
              "         [ 0.2594, -0.0383,  0.1276, -0.1858]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0100],\n",
              "         [0.0650],\n",
              "         [0.0915],\n",
              "         [0.1161],\n",
              "         [0.1386],\n",
              "         [0.1592],\n",
              "         [0.1782],\n",
              "         [0.1956],\n",
              "         [0.2116]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0100],\n",
              "         [0.1564],\n",
              "         [0.2037],\n",
              "         [0.2313],\n",
              "         [0.2503],\n",
              "         [0.2649],\n",
              "         [0.2772],\n",
              "         [0.2882],\n",
              "         [0.2984]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0100],\n",
              "         [0.1506],\n",
              "         [0.1884],\n",
              "         [0.2041],\n",
              "         [0.2095],\n",
              "         [0.2099],\n",
              "         [0.2076],\n",
              "         [0.2041],\n",
              "         [0.1999]], grad_fn=<DivBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=[None]*5000\n",
        "c_b1=[None]*5000\n",
        "b_b1=[None]*5000\n",
        "cp_b1=[None]*5000\n",
        "\n",
        "a_b2=[None]*5000\n",
        "c_b2=[None]*5000\n",
        "b_b2=[None]*5000\n",
        "cp_b2=[None]*5000\n",
        "a_b3=[None]*5000\n",
        "c_b3=[None]*5000\n",
        "b_b3=[None]*5000\n",
        "cp_b3=[None]*5000\n",
        "a_b4=[None]*5000\n",
        "c_b4=[None]*5000\n",
        "b_b4=[None]*5000\n",
        "cp_b4=[None]*5000\n",
        "a_b5=[None]*5000\n",
        "c_b5=[None]*5000\n",
        "b_b5=[None]*5000\n",
        "cp_b5=[None]*5000\n",
        "a_b6=[None]*5000\n",
        "c_b6=[None]*5000\n",
        "b_b6=[None]*5000\n",
        "cp_b6=[None]*5000\n",
        "a_b7=[None]*5000\n",
        "c_b7=[None]*5000\n",
        "b_b7=[None]*5000\n",
        "cp_b7=[None]*5000\n",
        "a_b8=[None]*5000\n",
        "c_b8=[None]*5000\n",
        "b_b8=[None]*5000\n",
        "cp_b8=[None]*5000\n",
        "a_b9=[None]*5000\n",
        "c_b9=[None]*5000\n",
        "b_b9=[None]*5000\n",
        "cp_b9=[None]*5000\n",
        "\n",
        "bi1=[None]*5000\n",
        "bi2=[None]*5000\n",
        "bi3=[None]*5000\n",
        "bi4=[None]*5000\n",
        "bi5=[None]*5000\n",
        "bi6=[None]*5000\n",
        "bi7=[None]*5000\n",
        "bi8=[None]*5000\n",
        "bi9=[None]*5000\n",
        "\n",
        "w1=[None]*5000\n",
        "w2=[None]*5000\n",
        "w3=[None]*5000\n",
        "w4=[None]*5000\n",
        "w5=[None]*5000\n",
        "w6=[None]*5000\n",
        "w7=[None]*5000\n",
        "w8=[None]*5000\n",
        "w9=[None]*5000\n",
        "\n",
        "xw1=[None]*5000\n",
        "xw2=[None]*5000\n",
        "xw3=[None]*5000\n",
        "xw4=[None]*5000\n",
        "xw5=[None]*5000\n",
        "xw6=[None]*5000\n",
        "xw7=[None]*5000\n",
        "xw8=[None]*5000\n",
        "xw9=[None]*5000\n",
        "fbi1=[None]*5000\n",
        "fbi2=[None]*5000\n",
        "fbi3=[None]*5000\n",
        "fbi4=[None]*5000\n",
        "fbi5=[None]*5000\n",
        "fbi6=[None]*5000\n",
        "fbi7=[None]*5000\n",
        "fbi8=[None]*5000\n",
        "fbi9=[None]*5000\n",
        "\n",
        "sbi1=[None]*5000\n",
        "sbi2=[None]*5000\n",
        "sbi3=[None]*5000\n",
        "sbi4=[None]*5000\n",
        "sbi5=[None]*5000\n",
        "sbi6=[None]*5000\n",
        "sbi7=[None]*5000\n",
        "sbi8=[None]*5000\n",
        "sbi9=[None]*5000"
      ],
      "metadata": {
        "id": "qlQmT07bLxzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "XknFvWtwPdQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#부트스트랩 표본\n",
        "for i in tqdm(range(0,5000)):\n",
        "  new_data=data.sample(n=1332,replace=True,random_state=i)\n",
        "  parameters=gpbdl1(new_data)\n",
        "  a_b1[i]= parameters[0][0].detach()\n",
        "  c_b1[i]= parameters[2][0][0].detach()\n",
        "  b_b1[i]= parameters[2][0][3].detach()\n",
        "  cp_b1[i]= parameters[4][0].detach()\n",
        "  a_b2[i]= parameters[0][1].detach()\n",
        "  c_b2[i]= parameters[2][1][0].detach()\n",
        "  b_b2[i]= parameters[2][1][3].detach()\n",
        "  cp_b2[i]= parameters[4][1].detach()\n",
        "  a_b3[i]= parameters[0][2].detach()\n",
        "  c_b3[i]= parameters[2][2][0].detach()\n",
        "  b_b3[i]= parameters[2][2][3].detach()\n",
        "  cp_b3[i]= parameters[4][2].detach()\n",
        "  a_b4[i]= parameters[0][3].detach()\n",
        "  c_b4[i]= parameters[2][3][0].detach()\n",
        "  b_b4[i]= parameters[2][3][3].detach()\n",
        "  cp_b4[i]= parameters[4][3].detach()\n",
        "  a_b5[i]= parameters[0][4].detach()\n",
        "  c_b5[i]= parameters[2][4][0].detach()\n",
        "  b_b5[i]= parameters[2][4][3].detach()\n",
        "  cp_b5[i]= parameters[4][4].detach()\n",
        "  a_b6[i]= parameters[0][5].detach()\n",
        "  c_b6[i]= parameters[2][5][0].detach()\n",
        "  b_b6[i]= parameters[2][5][3].detach()\n",
        "  cp_b6[i]= parameters[4][5].detach()\n",
        "  a_b7[i]= parameters[0][6].detach()\n",
        "  c_b7[i]= parameters[2][6][0].detach()\n",
        "  b_b7[i]= parameters[2][6][3].detach()\n",
        "  cp_b7[i]= parameters[4][6].detach()\n",
        "  a_b8[i]= parameters[0][7].detach()\n",
        "  c_b8[i]= parameters[2][7][0].detach()\n",
        "  b_b8[i]= parameters[2][7][3].detach()\n",
        "  cp_b8[i]= parameters[4][7].detach()\n",
        "  a_b9[i]= parameters[0][8].detach()\n",
        "  c_b9[i]= parameters[2][8][0].detach()\n",
        "  b_b9[i]= parameters[2][8][3].detach()\n",
        "  cp_b9[i]= parameters[4][8].detach()\n",
        "  bi1[i]=parameters[3][0].detach()\n",
        "  bi2[i]=parameters[3][1].detach()\n",
        "  bi3[i]=parameters[3][2].detach()\n",
        "  bi4[i]=parameters[3][3].detach()\n",
        "  bi5[i]=parameters[3][4].detach()\n",
        "  bi6[i]=parameters[3][5].detach()\n",
        "  bi7[i]=parameters[3][6].detach()\n",
        "  bi8[i]=parameters[3][7].detach()\n",
        "  bi9[i]=parameters[3][8].detach()\n",
        "  w1[i]=parameters[2][0][1].detach()\n",
        "  w2[i]=parameters[2][1][1].detach()\n",
        "  w3[i]=parameters[2][2][1].detach()\n",
        "  w4[i]=parameters[2][3][1].detach()\n",
        "  w5[i]=parameters[2][4][1].detach()\n",
        "  w6[i]=parameters[2][5][1].detach()\n",
        "  w7[i]=parameters[2][6][1].detach()\n",
        "  w8[i]=parameters[2][7][1].detach()\n",
        "  w9[i]=parameters[2][8][1].detach()\n",
        "  xw1[i]=parameters[2][0][2].detach()\n",
        "  xw2[i]=parameters[2][1][2].detach()\n",
        "  xw3[i]=parameters[2][2][2].detach()\n",
        "  xw4[i]=parameters[2][3][2].detach()\n",
        "  xw5[i]=parameters[2][4][2].detach()\n",
        "  xw6[i]=parameters[2][5][2].detach()\n",
        "  xw7[i]=parameters[2][6][2].detach()\n",
        "  xw8[i]=parameters[2][7][2].detach()\n",
        "  xw9[i]=parameters[2][8][2].detach()\n",
        "\n",
        "  fbi1[i]=parameters[1][0].detach()\n",
        "  fbi2[i]=parameters[1][1].detach()\n",
        "  fbi3[i]=parameters[1][2].detach()\n",
        "  fbi4[i]=parameters[1][3].detach()\n",
        "  fbi5[i]=parameters[1][4].detach()\n",
        "  fbi6[i]=parameters[1][5].detach()\n",
        "  fbi7[i]=parameters[1][6].detach()\n",
        "  fbi8[i]=parameters[1][7].detach()\n",
        "  fbi9[i]=parameters[1][8].detach()\n",
        "\n",
        "  sbi1[i]=parameters[5][0].detach()\n",
        "  sbi2[i]=parameters[5][1].detach()\n",
        "  sbi3[i]=parameters[5][2].detach()\n",
        "  sbi4[i]=parameters[5][3].detach()\n",
        "  sbi5[i]=parameters[5][4].detach()\n",
        "  sbi6[i]=parameters[5][5].detach()\n",
        "  sbi7[i]=parameters[5][6].detach()\n",
        "  sbi8[i]=parameters[5][7].detach()\n",
        "  sbi9[i]=parameters[5][8].detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGICOlo3mJMc",
        "outputId": "81b1df73-4511-4c04-adae-002b7821352a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [4:26:23<00:00,  3.20s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('a_b1',a_b1)\n",
        "np.save('b_b1',b_b1)\n",
        "np.save('c_b1',c_b1)\n",
        "np.save('cp_b1',cp_b1)\n",
        "np.save('a_b2',a_b2)\n",
        "np.save('b_b2',b_b2)\n",
        "np.save('c_b2',c_b2)\n",
        "np.save('cp_b2',cp_b2)\n",
        "np.save('a_b3',a_b3)\n",
        "np.save('b_b3',b_b3)\n",
        "np.save('c_b3',c_b3)\n",
        "np.save('cp_b3',cp_b3)\n",
        "np.save('a_b4',a_b4)\n",
        "np.save('b_b4',b_b4)\n",
        "np.save('c_b4',c_b4)\n",
        "np.save('cp_b4',cp_b4)\n",
        "np.save('a_b5',a_b5)\n",
        "np.save('b_b5',b_b5)\n",
        "np.save('c_b5',c_b5)\n",
        "np.save('cp_b5',cp_b5)\n",
        "np.save('a_b6',a_b6)\n",
        "np.save('b_b6',b_b6)\n",
        "np.save('c_b6',c_b6)\n",
        "np.save('cp_b6',cp_b6)\n",
        "np.save('a_b7',a_b7)\n",
        "np.save('b_b7',b_b7)\n",
        "np.save('c_b7',c_b7)\n",
        "np.save('cp_b7',cp_b7)\n",
        "np.save('a_b8',a_b8)\n",
        "np.save('b_b8',b_b8)\n",
        "np.save('c_b8',c_b8)\n",
        "np.save('cp_b8',cp_b8)\n",
        "np.save('a_b9',a_b9)\n",
        "np.save('b_b9',b_b9)\n",
        "np.save('c_b9',c_b9)\n",
        "np.save('cp_b9',cp_b9)\n",
        "np.save('bi1',bi1)\n",
        "np.save('bi2',bi2)\n",
        "np.save('bi3',bi3)\n",
        "np.save('bi4',bi4)\n",
        "np.save('bi5',bi5)\n",
        "np.save('bi6',bi6)\n",
        "np.save('bi7',bi7)\n",
        "np.save('bi8',bi8)\n",
        "np.save('bi9',bi9)\n",
        "np.save('w1',w1)\n",
        "np.save('w2',w2)\n",
        "np.save('w3',w3)\n",
        "np.save('w4',w4)\n",
        "np.save('w5',w5)\n",
        "np.save('w6',w6)\n",
        "np.save('w7',w7)\n",
        "np.save('w8',w8)\n",
        "np.save('w9',w9)\n",
        "np.save('xw1',xw1)\n",
        "np.save('xw2',xw2)\n",
        "np.save('xw3',xw3)\n",
        "np.save('xw4',xw4)\n",
        "np.save('xw5',xw5)\n",
        "np.save('xw6',xw6)\n",
        "np.save('xw7',xw7)\n",
        "np.save('xw8',xw8)\n",
        "np.save('xw9',xw9)\n",
        "\n",
        "np.save('fbi1',fbi1)\n",
        "np.save('fbi2',fbi2)\n",
        "np.save('fbi3',fbi3)\n",
        "np.save('fbi4',fbi4)\n",
        "np.save('fbi5',fbi5)\n",
        "np.save('fbi6',fbi6)\n",
        "np.save('fbi7',fbi7)\n",
        "np.save('fbi8',fbi8)\n",
        "np.save('fbi9',fbi9)\n",
        "\n",
        "np.save('sbi1',sbi1)\n",
        "np.save('sbi2',sbi2)\n",
        "np.save('sbi3',sbi3)\n",
        "np.save('sbi4',sbi4)\n",
        "np.save('sbi5',sbi5)\n",
        "np.save('sbi6',sbi6)\n",
        "np.save('sbi7',sbi7)\n",
        "np.save('sbi8',sbi8)\n",
        "np.save('sbi9',sbi9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxeIS8etmJS_",
        "outputId": "6c3c509f-f781-4275-b70a-11b3f5c5c5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:521: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  arr = np.asanyarray(arr)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F0vuQLOem-Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=np.load('a_b1.npy',allow_pickle=True)\n",
        "b_b1=np.load('b_b1.npy',allow_pickle=True)\n",
        "c_b1=np.load('c_b1.npy',allow_pickle=True)\n",
        "cp_b1=np.load('cp_b1.npy',allow_pickle=True)\n",
        "ab_b1=a_b1*b_b1\n",
        "a_b2=np.load('a_b2.npy',allow_pickle=True)\n",
        "b_b2=np.load('b_b2.npy',allow_pickle=True)\n",
        "c_b2=np.load('c_b2.npy',allow_pickle=True)\n",
        "cp_b2=np.load('cp_b2.npy',allow_pickle=True)\n",
        "ab_b2=a_b2*b_b2\n",
        "a_b3=np.load('a_b3.npy',allow_pickle=True)\n",
        "b_b3=np.load('b_b3.npy',allow_pickle=True)\n",
        "c_b3=np.load('c_b3.npy',allow_pickle=True)\n",
        "cp_b3=np.load('cp_b3.npy',allow_pickle=True)\n",
        "ab_b3=a_b3*b_b3\n",
        "a_b4=np.load('a_b4.npy',allow_pickle=True)\n",
        "b_b4=np.load('b_b4.npy',allow_pickle=True)\n",
        "c_b4=np.load('c_b4.npy',allow_pickle=True)\n",
        "cp_b4=np.load('cp_b4.npy',allow_pickle=True)\n",
        "ab_b4=a_b4*b_b4\n",
        "a_b5=np.load('a_b5.npy',allow_pickle=True)\n",
        "b_b5=np.load('b_b5.npy',allow_pickle=True)\n",
        "c_b5=np.load('c_b5.npy',allow_pickle=True)\n",
        "cp_b5=np.load('cp_b5.npy',allow_pickle=True)\n",
        "ab_b5=a_b5*b_b5\n",
        "a_b6=np.load('a_b6.npy',allow_pickle=True)\n",
        "b_b6=np.load('b_b6.npy',allow_pickle=True)\n",
        "c_b6=np.load('c_b6.npy',allow_pickle=True)\n",
        "cp_b6=np.load('cp_b6.npy',allow_pickle=True)\n",
        "ab_b6=a_b6*b_b6\n",
        "a_b7=np.load('a_b7.npy',allow_pickle=True)\n",
        "b_b7=np.load('b_b7.npy',allow_pickle=True)\n",
        "c_b7=np.load('c_b7.npy',allow_pickle=True)\n",
        "cp_b7=np.load('cp_b7.npy',allow_pickle=True)\n",
        "ab_b7=a_b7*b_b7\n",
        "a_b8=np.load('a_b8.npy',allow_pickle=True)\n",
        "b_b8=np.load('b_b8.npy',allow_pickle=True)\n",
        "c_b8=np.load('c_b8.npy',allow_pickle=True)\n",
        "cp_b8=np.load('cp_b8.npy',allow_pickle=True)\n",
        "ab_b8=a_b8*b_b8\n",
        "a_b9=np.load('a_b9.npy',allow_pickle=True)\n",
        "b_b9=np.load('b_b9.npy',allow_pickle=True)\n",
        "c_b9=np.load('c_b9.npy',allow_pickle=True)\n",
        "cp_b9=np.load('cp_b9.npy',allow_pickle=True)\n",
        "ab_b9=a_b9*b_b9\n",
        "bi1=np.load('bi1.npy',allow_pickle=True)\n",
        "bi2=np.load('bi2.npy',allow_pickle=True)\n",
        "bi3=np.load('bi3.npy',allow_pickle=True)\n",
        "bi4=np.load('bi4.npy',allow_pickle=True)\n",
        "bi5=np.load('bi5.npy',allow_pickle=True)\n",
        "bi6=np.load('bi6.npy',allow_pickle=True)\n",
        "bi7=np.load('bi7.npy',allow_pickle=True)\n",
        "bi8=np.load('bi8.npy',allow_pickle=True)\n",
        "bi9=np.load('bi9.npy',allow_pickle=True)\n",
        "w1=np.load('w1.npy',allow_pickle=True)\n",
        "w2=np.load('w2.npy',allow_pickle=True)\n",
        "w3=np.load('w3.npy',allow_pickle=True)\n",
        "w4=np.load('w4.npy',allow_pickle=True)\n",
        "w5=np.load('w5.npy',allow_pickle=True)\n",
        "w6=np.load('w6.npy',allow_pickle=True)\n",
        "w7=np.load('w7.npy',allow_pickle=True)\n",
        "w8=np.load('w8.npy',allow_pickle=True)\n",
        "w9=np.load('w9.npy',allow_pickle=True)\n",
        "xw1=np.load('xw1.npy',allow_pickle=True)\n",
        "xw2=np.load('xw2.npy',allow_pickle=True)\n",
        "xw3=np.load('xw3.npy',allow_pickle=True)\n",
        "xw4=np.load('xw4.npy',allow_pickle=True)\n",
        "xw5=np.load('xw5.npy',allow_pickle=True)\n",
        "xw6=np.load('xw6.npy',allow_pickle=True)\n",
        "xw7=np.load('xw7.npy',allow_pickle=True)\n",
        "xw8=np.load('xw8.npy',allow_pickle=True)\n",
        "xw9=np.load('xw9.npy',allow_pickle=True)\n",
        "fbi1=np.load('fbi1.npy',allow_pickle=True)\n",
        "fbi2=np.load('fbi2.npy',allow_pickle=True)\n",
        "fbi3=np.load('fbi3.npy',allow_pickle=True)\n",
        "fbi4=np.load('fbi4.npy',allow_pickle=True)\n",
        "fbi5=np.load('fbi5.npy',allow_pickle=True)\n",
        "fbi6=np.load('fbi6.npy',allow_pickle=True)\n",
        "fbi7=np.load('fbi7.npy',allow_pickle=True)\n",
        "fbi8=np.load('fbi8.npy',allow_pickle=True)\n",
        "fbi9=np.load('fbi9.npy',allow_pickle=True)"
      ],
      "metadata": {
        "id": "RU4e2QP5mJZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1= a_b1.tolist()\n",
        "b_b1= b_b1.tolist()\n",
        "c_b1= c_b1.tolist()\n",
        "cp_b1= cp_b1.tolist()\n",
        "ab_b1= ab_b1.tolist()\n",
        "a_b2= a_b2.tolist()\n",
        "b_b2= b_b2.tolist()\n",
        "c_b2= c_b2.tolist()\n",
        "cp_b2= cp_b2.tolist()\n",
        "ab_b2= ab_b2.tolist()\n",
        "a_b3= a_b3.tolist()\n",
        "b_b3= b_b3.tolist()\n",
        "c_b3= c_b3.tolist()\n",
        "cp_b3= cp_b3.tolist()\n",
        "ab_b3= ab_b3.tolist()\n",
        "a_b4= a_b4.tolist()\n",
        "b_b4= b_b4.tolist()\n",
        "c_b4= c_b4.tolist()\n",
        "cp_b4= cp_b4.tolist()\n",
        "ab_b4= ab_b4.tolist()\n",
        "a_b5= a_b5.tolist()\n",
        "b_b5= b_b5.tolist()\n",
        "c_b5= c_b5.tolist()\n",
        "cp_b5= cp_b5.tolist()\n",
        "ab_b5= ab_b5.tolist()\n",
        "a_b6= a_b6.tolist()\n",
        "b_b6= b_b6.tolist()\n",
        "c_b6= c_b6.tolist()\n",
        "cp_b6= cp_b6.tolist()\n",
        "ab_b6= ab_b6.tolist()\n",
        "a_b7= a_b7.tolist()\n",
        "b_b7= b_b7.tolist()\n",
        "c_b7= c_b7.tolist()\n",
        "cp_b7= cp_b7.tolist()\n",
        "ab_b7= ab_b7.tolist()\n",
        "a_b8= a_b8.tolist()\n",
        "b_b8= b_b8.tolist()\n",
        "c_b8= c_b8.tolist()\n",
        "cp_b8= cp_b8.tolist()\n",
        "ab_b8= ab_b8.tolist()\n",
        "a_b9= a_b9.tolist()\n",
        "b_b9= b_b9.tolist()\n",
        "c_b9= c_b9.tolist()\n",
        "cp_b9= cp_b9.tolist()\n",
        "ab_b9= ab_b9.tolist()\n",
        "bi1=bi1.tolist()\n",
        "bi2=bi2.tolist()\n",
        "bi3=bi3.tolist()\n",
        "bi4=bi4.tolist()\n",
        "bi5=bi5.tolist()\n",
        "bi6=bi6.tolist()\n",
        "bi7=bi7.tolist()\n",
        "bi8=bi8.tolist()\n",
        "bi9=bi9.tolist()\n",
        "w1=w1.tolist()\n",
        "w2=w2.tolist()\n",
        "w3=w3.tolist()\n",
        "w4=w4.tolist()\n",
        "w5=w5.tolist()\n",
        "w6=w6.tolist()\n",
        "w7=w7.tolist()\n",
        "w8=w8.tolist()\n",
        "w9=w9.tolist()\n",
        "xw1=xw1.tolist()\n",
        "xw2=xw2.tolist()\n",
        "xw3=xw3.tolist()\n",
        "xw4=xw4.tolist()\n",
        "xw5=xw5.tolist()\n",
        "xw6=xw6.tolist()\n",
        "xw7=xw7.tolist()\n",
        "xw8=xw8.tolist()\n",
        "xw9=xw9.tolist()\n",
        "fbi1=fbi1.tolist()\n",
        "fbi2=fbi2.tolist()\n",
        "fbi3=fbi3.tolist()\n",
        "fbi4=fbi4.tolist()\n",
        "fbi5=fbi5.tolist()\n",
        "fbi6=fbi6.tolist()\n",
        "fbi7=fbi7.tolist()\n",
        "fbi8=fbi8.tolist()\n",
        "fbi9=fbi9.tolist()"
      ],
      "metadata": {
        "id": "dHirDpP6thcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=np.array(a_b1)\n",
        "b_b1=np.array(b_b1)\n",
        "c_b1=np.array(c_b1)\n",
        "cp_b1=np.array(cp_b1)\n",
        "ab_b1=np.array(ab_b1)\n",
        "a_b2=np.array(a_b2)\n",
        "b_b2=np.array(b_b2)\n",
        "c_b2=np.array(c_b2)\n",
        "cp_b2=np.array(cp_b2)\n",
        "ab_b2=np.array(ab_b2)\n",
        "a_b3=np.array(a_b3)\n",
        "b_b3=np.array(b_b3)\n",
        "c_b3=np.array(c_b3)\n",
        "cp_b3=np.array(cp_b3)\n",
        "ab_b3=np.array(ab_b3)\n",
        "a_b4=np.array(a_b4)\n",
        "b_b4=np.array(b_b4)\n",
        "c_b4=np.array(c_b4)\n",
        "cp_b4=np.array(cp_b4)\n",
        "ab_b4=np.array(ab_b4)\n",
        "a_b5=np.array(a_b5)\n",
        "b_b5=np.array(b_b5)\n",
        "c_b5=np.array(c_b5)\n",
        "cp_b5=np.array(cp_b5)\n",
        "ab_b5=np.array(ab_b5)\n",
        "a_b6=np.array(a_b6)\n",
        "b_b6=np.array(b_b6)\n",
        "c_b6=np.array(c_b6)\n",
        "cp_b6=np.array(cp_b6)\n",
        "ab_b6=np.array(ab_b6)\n",
        "a_b7=np.array(a_b7)\n",
        "b_b7=np.array(b_b7)\n",
        "c_b7=np.array(c_b7)\n",
        "cp_b7=np.array(cp_b7)\n",
        "ab_b7=np.array(ab_b7)\n",
        "a_b8=np.array(a_b8)\n",
        "b_b8=np.array(b_b8)\n",
        "c_b8=np.array(c_b8)\n",
        "cp_b8=np.array(cp_b8)\n",
        "ab_b8=np.array(ab_b8)\n",
        "a_b9=np.array(a_b9)\n",
        "b_b9=np.array(b_b9)\n",
        "c_b9=np.array(c_b9)\n",
        "cp_b9=np.array(cp_b9)\n",
        "ab_b9=np.array(ab_b9)\n",
        "bi1=np.array(bi1)\n",
        "bi2=np.array(bi2)\n",
        "bi3=np.array(bi3)\n",
        "bi4=np.array(bi4)\n",
        "bi5=np.array(bi5)\n",
        "bi6=np.array(bi6)\n",
        "bi7=np.array(bi7)\n",
        "bi8=np.array(bi8)\n",
        "bi9=np.array(bi9)\n",
        "\n",
        "w1=np.array(w1)\n",
        "w2=np.array(w2)\n",
        "w3=np.array(w3)\n",
        "w4=np.array(w4)\n",
        "w5=np.array(w5)\n",
        "w6=np.array(w6)\n",
        "w7=np.array(w7)\n",
        "w8=np.array(w8)\n",
        "w9=np.array(w9)\n",
        "\n",
        "xw1=np.array(xw1)\n",
        "xw2=np.array(xw2)\n",
        "xw3=np.array(xw3)\n",
        "xw4=np.array(xw4)\n",
        "xw5=np.array(xw5)\n",
        "xw6=np.array(xw6)\n",
        "xw7=np.array(xw7)\n",
        "xw8=np.array(xw8)\n",
        "xw9=np.array(xw9)\n",
        "fbi1=np.array(fbi1)\n",
        "fbi2=np.array(fbi2)\n",
        "fbi3=np.array(fbi3)\n",
        "fbi4=np.array(fbi4)\n",
        "fbi5=np.array(fbi5)\n",
        "fbi6=np.array(fbi6)\n",
        "fbi7=np.array(fbi7)\n",
        "fbi8=np.array(fbi8)\n",
        "fbi9=np.array(fbi9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdAVilXtdwyc",
        "outputId": "0c3d0988-d25e-4691-bc07-43450ad8230b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-5404b8a9f43c>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b1=np.array(a_b1)\n",
            "<ipython-input-10-5404b8a9f43c>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b1=np.array(a_b1)\n",
            "<ipython-input-10-5404b8a9f43c>:4: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b1=np.array(cp_b1)\n",
            "<ipython-input-10-5404b8a9f43c>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b1=np.array(cp_b1)\n",
            "<ipython-input-10-5404b8a9f43c>:5: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b1=np.array(ab_b1)\n",
            "<ipython-input-10-5404b8a9f43c>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b1=np.array(ab_b1)\n",
            "<ipython-input-10-5404b8a9f43c>:6: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b2=np.array(a_b2)\n",
            "<ipython-input-10-5404b8a9f43c>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b2=np.array(a_b2)\n",
            "<ipython-input-10-5404b8a9f43c>:9: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b2=np.array(cp_b2)\n",
            "<ipython-input-10-5404b8a9f43c>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b2=np.array(cp_b2)\n",
            "<ipython-input-10-5404b8a9f43c>:10: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b2=np.array(ab_b2)\n",
            "<ipython-input-10-5404b8a9f43c>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b2=np.array(ab_b2)\n",
            "<ipython-input-10-5404b8a9f43c>:11: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b3=np.array(a_b3)\n",
            "<ipython-input-10-5404b8a9f43c>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b3=np.array(a_b3)\n",
            "<ipython-input-10-5404b8a9f43c>:14: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b3=np.array(cp_b3)\n",
            "<ipython-input-10-5404b8a9f43c>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b3=np.array(cp_b3)\n",
            "<ipython-input-10-5404b8a9f43c>:15: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b3=np.array(ab_b3)\n",
            "<ipython-input-10-5404b8a9f43c>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b3=np.array(ab_b3)\n",
            "<ipython-input-10-5404b8a9f43c>:16: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b4=np.array(a_b4)\n",
            "<ipython-input-10-5404b8a9f43c>:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b4=np.array(a_b4)\n",
            "<ipython-input-10-5404b8a9f43c>:19: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b4=np.array(cp_b4)\n",
            "<ipython-input-10-5404b8a9f43c>:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b4=np.array(cp_b4)\n",
            "<ipython-input-10-5404b8a9f43c>:20: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b4=np.array(ab_b4)\n",
            "<ipython-input-10-5404b8a9f43c>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b4=np.array(ab_b4)\n",
            "<ipython-input-10-5404b8a9f43c>:21: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b5=np.array(a_b5)\n",
            "<ipython-input-10-5404b8a9f43c>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b5=np.array(a_b5)\n",
            "<ipython-input-10-5404b8a9f43c>:24: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b5=np.array(cp_b5)\n",
            "<ipython-input-10-5404b8a9f43c>:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b5=np.array(cp_b5)\n",
            "<ipython-input-10-5404b8a9f43c>:25: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b5=np.array(ab_b5)\n",
            "<ipython-input-10-5404b8a9f43c>:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b5=np.array(ab_b5)\n",
            "<ipython-input-10-5404b8a9f43c>:26: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b6=np.array(a_b6)\n",
            "<ipython-input-10-5404b8a9f43c>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b6=np.array(a_b6)\n",
            "<ipython-input-10-5404b8a9f43c>:29: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b6=np.array(cp_b6)\n",
            "<ipython-input-10-5404b8a9f43c>:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b6=np.array(cp_b6)\n",
            "<ipython-input-10-5404b8a9f43c>:30: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b6=np.array(ab_b6)\n",
            "<ipython-input-10-5404b8a9f43c>:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b6=np.array(ab_b6)\n",
            "<ipython-input-10-5404b8a9f43c>:31: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b7=np.array(a_b7)\n",
            "<ipython-input-10-5404b8a9f43c>:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b7=np.array(a_b7)\n",
            "<ipython-input-10-5404b8a9f43c>:34: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b7=np.array(cp_b7)\n",
            "<ipython-input-10-5404b8a9f43c>:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b7=np.array(cp_b7)\n",
            "<ipython-input-10-5404b8a9f43c>:35: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b7=np.array(ab_b7)\n",
            "<ipython-input-10-5404b8a9f43c>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b7=np.array(ab_b7)\n",
            "<ipython-input-10-5404b8a9f43c>:36: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b8=np.array(a_b8)\n",
            "<ipython-input-10-5404b8a9f43c>:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b8=np.array(a_b8)\n",
            "<ipython-input-10-5404b8a9f43c>:39: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b8=np.array(cp_b8)\n",
            "<ipython-input-10-5404b8a9f43c>:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b8=np.array(cp_b8)\n",
            "<ipython-input-10-5404b8a9f43c>:40: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b8=np.array(ab_b8)\n",
            "<ipython-input-10-5404b8a9f43c>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b8=np.array(ab_b8)\n",
            "<ipython-input-10-5404b8a9f43c>:41: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b9=np.array(a_b9)\n",
            "<ipython-input-10-5404b8a9f43c>:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b9=np.array(a_b9)\n",
            "<ipython-input-10-5404b8a9f43c>:44: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b9=np.array(cp_b9)\n",
            "<ipython-input-10-5404b8a9f43c>:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b9=np.array(cp_b9)\n",
            "<ipython-input-10-5404b8a9f43c>:45: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b9=np.array(ab_b9)\n",
            "<ipython-input-10-5404b8a9f43c>:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b9=np.array(ab_b9)\n",
            "<ipython-input-10-5404b8a9f43c>:46: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi1=np.array(bi1)\n",
            "<ipython-input-10-5404b8a9f43c>:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi1=np.array(bi1)\n",
            "<ipython-input-10-5404b8a9f43c>:47: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi2=np.array(bi2)\n",
            "<ipython-input-10-5404b8a9f43c>:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi2=np.array(bi2)\n",
            "<ipython-input-10-5404b8a9f43c>:48: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi3=np.array(bi3)\n",
            "<ipython-input-10-5404b8a9f43c>:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi3=np.array(bi3)\n",
            "<ipython-input-10-5404b8a9f43c>:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi4=np.array(bi4)\n",
            "<ipython-input-10-5404b8a9f43c>:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi4=np.array(bi4)\n",
            "<ipython-input-10-5404b8a9f43c>:50: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi5=np.array(bi5)\n",
            "<ipython-input-10-5404b8a9f43c>:50: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi5=np.array(bi5)\n",
            "<ipython-input-10-5404b8a9f43c>:51: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi6=np.array(bi6)\n",
            "<ipython-input-10-5404b8a9f43c>:51: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi6=np.array(bi6)\n",
            "<ipython-input-10-5404b8a9f43c>:52: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi7=np.array(bi7)\n",
            "<ipython-input-10-5404b8a9f43c>:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi7=np.array(bi7)\n",
            "<ipython-input-10-5404b8a9f43c>:53: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi8=np.array(bi8)\n",
            "<ipython-input-10-5404b8a9f43c>:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi8=np.array(bi8)\n",
            "<ipython-input-10-5404b8a9f43c>:54: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi9=np.array(bi9)\n",
            "<ipython-input-10-5404b8a9f43c>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi9=np.array(bi9)\n",
            "<ipython-input-10-5404b8a9f43c>:75: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi1=np.array(fbi1)\n",
            "<ipython-input-10-5404b8a9f43c>:75: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi1=np.array(fbi1)\n",
            "<ipython-input-10-5404b8a9f43c>:76: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi2=np.array(fbi2)\n",
            "<ipython-input-10-5404b8a9f43c>:76: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi2=np.array(fbi2)\n",
            "<ipython-input-10-5404b8a9f43c>:77: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi3=np.array(fbi3)\n",
            "<ipython-input-10-5404b8a9f43c>:77: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi3=np.array(fbi3)\n",
            "<ipython-input-10-5404b8a9f43c>:78: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi4=np.array(fbi4)\n",
            "<ipython-input-10-5404b8a9f43c>:78: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi4=np.array(fbi4)\n",
            "<ipython-input-10-5404b8a9f43c>:79: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi5=np.array(fbi5)\n",
            "<ipython-input-10-5404b8a9f43c>:79: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi5=np.array(fbi5)\n",
            "<ipython-input-10-5404b8a9f43c>:80: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi6=np.array(fbi6)\n",
            "<ipython-input-10-5404b8a9f43c>:80: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi6=np.array(fbi6)\n",
            "<ipython-input-10-5404b8a9f43c>:81: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi7=np.array(fbi7)\n",
            "<ipython-input-10-5404b8a9f43c>:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi7=np.array(fbi7)\n",
            "<ipython-input-10-5404b8a9f43c>:82: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi8=np.array(fbi8)\n",
            "<ipython-input-10-5404b8a9f43c>:82: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi8=np.array(fbi8)\n",
            "<ipython-input-10-5404b8a9f43c>:83: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  fbi9=np.array(fbi9)\n",
            "<ipython-input-10-5404b8a9f43c>:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  fbi9=np.array(fbi9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_1=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_1[i]=bi1[i].item()\n",
        "bi_2=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_2[i]=bi2[i].item()\n",
        "bi_3=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_3[i]=bi3[i].item()\n",
        "bi_4=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_4[i]=bi4[i].item()\n",
        "bi_5=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_5[i]=bi5[i].item()\n",
        "bi_6=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_6[i]=bi6[i].item()\n",
        "bi_7=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_7[i]=bi7[i].item()\n",
        "bi_8=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_8[i]=bi8[i].item()\n",
        "bi_9=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_9[i]=bi9[i].item()\n"
      ],
      "metadata": {
        "id": "u1AWzSmPk1ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics"
      ],
      "metadata": {
        "id": "4w85XrH-pI2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fbi1=np.asarray(fbi1,dtype=np.float64)\n",
        "fbi2=np.asarray(fbi2,dtype=np.float64)\n",
        "fbi3=np.asarray(fbi3,dtype=np.float64)\n",
        "fbi4=np.asarray(fbi4,dtype=np.float64)\n",
        "fbi5=np.asarray(fbi5,dtype=np.float64)\n",
        "fbi6=np.asarray(fbi6,dtype=np.float64)\n",
        "fbi7=np.asarray(fbi7,dtype=np.float64)\n",
        "fbi8=np.asarray(fbi8,dtype=np.float64)\n",
        "fbi9=np.asarray(fbi9,dtype=np.float64)\n",
        "a1=np.asarray(a_b1,dtype=np.float64)\n",
        "a2=np.asarray(a_b2,dtype=np.float64)\n",
        "a3=np.asarray(a_b3,dtype=np.float64)\n",
        "a4=np.asarray(a_b4,dtype=np.float64)\n",
        "a5=np.asarray(a_b5,dtype=np.float64)\n",
        "a6=np.asarray(a_b6,dtype=np.float64)\n",
        "a7=np.asarray(a_b7,dtype=np.float64)\n",
        "a8=np.asarray(a_b8,dtype=np.float64)\n",
        "a9=np.asarray(a_b9,dtype=np.float64)"
      ],
      "metadata": {
        "id": "b6RZK4q8eKwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=[None]*9\n",
        "b=[None]*9\n",
        "bi=[None]*9\n",
        "w=[None]*9\n",
        "xw=[None]*9\n",
        "a=[None]*9\n",
        "fbi=[None]*9\n",
        "c[0]=c_b1.mean()\n",
        "b[0]=b_b1.mean()\n",
        "bi[0]=statistics.mean(bi_1)\n",
        "c[1]=c_b2.mean()\n",
        "b[1]=b_b2.mean()\n",
        "bi[1]=statistics.mean(bi_2)\n",
        "c[2]=c_b3.mean()\n",
        "b[2]=b_b3.mean()\n",
        "bi[2]=statistics.mean(bi_3)\n",
        "c[3]=c_b4.mean()\n",
        "b[3]=b_b4.mean()\n",
        "bi[3]=statistics.mean(bi_4)\n",
        "c[4]=c_b5.mean()\n",
        "b[4]=b_b5.mean()\n",
        "bi[4]=statistics.mean(bi_5)\n",
        "c[5]=c_b6.mean()\n",
        "b[5]=b_b6.mean()\n",
        "bi[5]=statistics.mean(bi_6)\n",
        "c[6]=c_b7.mean()\n",
        "b[6]=b_b7.mean()\n",
        "bi[6]=statistics.mean(bi_7)\n",
        "c[7]=c_b8.mean()\n",
        "b[7]=b_b8.mean()\n",
        "bi[7]=statistics.mean(bi_8)\n",
        "c[8]=c_b9.mean()\n",
        "b[8]=b_b9.mean()\n",
        "bi[8]=statistics.mean(bi_9)\n",
        "w[0]=w1.mean()\n",
        "w[1]=w2.mean()\n",
        "w[2]=w3.mean()\n",
        "w[3]=w4.mean()\n",
        "w[4]=w5.mean()\n",
        "w[5]=w6.mean()\n",
        "w[6]=w7.mean()\n",
        "w[7]=w8.mean()\n",
        "w[8]=w9.mean()\n",
        "\n",
        "xw[0]=xw1.mean()\n",
        "xw[1]=xw2.mean()\n",
        "xw[2]=xw3.mean()\n",
        "xw[3]=xw4.mean()\n",
        "xw[4]=xw5.mean()\n",
        "xw[5]=xw6.mean()\n",
        "xw[6]=xw7.mean()\n",
        "xw[7]=xw8.mean()\n",
        "xw[8]=xw9.mean()\n",
        "a[0]=a1.mean()\n",
        "a[1]=a2.mean()\n",
        "a[2]=a3.mean()\n",
        "a[3]=a4.mean()\n",
        "a[4]=a5.mean()\n",
        "a[5]=a6.mean()\n",
        "a[6]=a7.mean()\n",
        "a[7]=a8.mean()\n",
        "a[8]=a9.mean()\n",
        "fbi[0]=fbi1.mean()\n",
        "fbi[1]=fbi2.mean()\n",
        "fbi[2]=fbi3.mean()\n",
        "fbi[3]=fbi4.mean()\n",
        "fbi[4]=fbi5.mean()\n",
        "fbi[5]=fbi6.mean()\n",
        "fbi[6]=fbi7.mean()\n",
        "fbi[7]=fbi8.mean()\n",
        "fbi[8]=fbi9.mean()"
      ],
      "metadata": {
        "id": "ovErcRjVfDH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bi[8],c[8],b[8],w[8],xw[8],fbi[8],a[8])"
      ],
      "metadata": {
        "id": "tNhCSrxdlYrR",
        "outputId": "cb121f4f-603f-4244-9705-82c7665c96fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2113202930599451 0.2591330782830715 -0.18545640248060227 -0.038249105736985804 0.1276342380732298 0.3751262450993061 0.3349533178627491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1= fbi[0] + a[0]*x\n",
        "m2= fbi[1] + a[1]*x\n",
        "m3= fbi[2] + a[2]*x\n",
        "m4= fbi[3] + a[3]*x\n",
        "m5= fbi[4] + a[4]*x\n",
        "m6= fbi[5] + a[5]*x\n",
        "m7= fbi[6] + a[6]*x\n",
        "m8= fbi[7] + a[7]*x\n",
        "m9= fbi[8] + a[8]*x"
      ],
      "metadata": {
        "id": "QDLDsw99eSc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_h1=bi[0]+c[0]*x+b[0]*m1+w[0]*w_v+xw[0]*xw_v\n",
        "y_h2=bi[1]+c[1]*x+b[1]*m2+w[1]*w_v+xw[1]*xw_v\n",
        "y_h3=bi[2]+c[2]*x+b[2]*m3+w[2]*w_v+xw[2]*xw_v\n",
        "y_h4=bi[3]+c[3]*x+b[3]*m4+w[3]*w_v+xw[3]*xw_v\n",
        "y_h5=bi[4]+c[4]*x+b[4]*m5+w[4]*w_v+xw[4]*xw_v\n",
        "y_h6=bi[5]+c[5]*x+b[5]*m6+w[5]*w_v+xw[5]*xw_v\n",
        "y_h7=bi[6]+c[6]*x+b[6]*m7+w[6]*w_v+xw[6]*xw_v\n",
        "y_h8=bi[7]+c[7]*x+b[7]*m8+w[7]*w_v+xw[7]*xw_v\n",
        "y_h9=bi[8]+c[8]*x+b[8]*m9+w[8]*w_v+xw[8]*xw_v\n"
      ],
      "metadata": {
        "id": "DVj7dGr7lq2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TSS = ((y-y.mean())**2).sum(axis=1).sum()\n",
        "SSR1 = ((y_h1-y.mean())**2).sum(axis=1).sum()\n",
        "SSE1 = ((y-y_h1)**2).sum(axis=1).sum()\n",
        "SSR2 = ((y_h2-y.mean())**2).sum(axis=1).sum()\n",
        "SSE2 = ((y-y_h2)**2).sum(axis=1).sum()\n",
        "SSR3 = ((y_h3-y.mean())**2).sum(axis=1).sum()\n",
        "SSE3 = ((y-y_h3)**2).sum(axis=1).sum()\n",
        "SSR4 = ((y_h4-y.mean())**2).sum(axis=1).sum()\n",
        "SSE4 = ((y-y_h4)**2).sum(axis=1).sum()\n",
        "SSR5 = ((y_h5-y.mean())**2).sum(axis=1).sum()\n",
        "SSE5 = ((y-y_h5)**2).sum(axis=1).sum()\n",
        "SSR6 = ((y_h6-y.mean())**2).sum(axis=1).sum()\n",
        "SSE6 = ((y-y_h6)**2).sum(axis=1).sum()\n",
        "SSR7 = ((y_h7-y.mean())**2).sum(axis=1).sum()\n",
        "SSE7 = ((y-y_h7)**2).sum(axis=1).sum()\n",
        "SSR8 = ((y_h8-y.mean())**2).sum(axis=1).sum()\n",
        "SSE8 = ((y-y_h8)**2).sum(axis=1).sum()\n",
        "SSR9 = ((y_h9-y.mean())**2).sum(axis=1).sum()\n",
        "SSE9 = ((y-y_h9)**2).sum(axis=1).sum()\n"
      ],
      "metadata": {
        "id": "6EuMdD-br6Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R2_1 = 1 - SSE1 / TSS\n",
        "print(R2_1)\n",
        "R2_2 = 1 - SSE2 / TSS\n",
        "print(R2_2)\n",
        "R2_3 = 1 - SSE3 / TSS\n",
        "print(R2_3)\n",
        "R2_4 = 1 - SSE4 / TSS\n",
        "print(R2_4)\n",
        "R2_5 = 1 - SSE5 / TSS\n",
        "print(R2_5)\n",
        "R2_6 = 1 - SSE6 / TSS\n",
        "print(R2_6)\n",
        "R2_7 = 1 - SSE7 / TSS\n",
        "print(R2_7)\n",
        "R2_8 = 1 - SSE8 / TSS\n",
        "print(R2_8)\n",
        "R2_9 = 1 - SSE9 / TSS\n",
        "print(R2_9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kzl2Me-sgPL",
        "outputId": "f2a51c3a-ad0c-4e08-a6a7-fa794da3bc65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.1400967992947133\n",
            "0.14412098274278917\n",
            "0.23238489356842673\n",
            "0.2791945721129573\n",
            "0.3077678970939318\n",
            "0.32699106808828293\n",
            "0.3407827537778704\n",
            "0.3510603378521606\n",
            "0.35886221853328526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSE1 = np.sqrt(((y-y_h1)**2).sum(axis=1).sum()/1332)\n",
        "MSE2 = np.sqrt(((y-y_h2)**2).sum(axis=1).sum()/1332)\n",
        "MSE3 = np.sqrt(((y-y_h3)**2).sum(axis=1).sum()/1332)\n",
        "MSE4 = np.sqrt(((y-y_h4)**2).sum(axis=1).sum()/1332)\n",
        "MSE5 = np.sqrt(((y-y_h5)**2).sum(axis=1).sum()/1332)\n",
        "MSE6 = np.sqrt(((y-y_h6)**2).sum(axis=1).sum()/1332)\n",
        "MSE7 = np.sqrt(((y-y_h7)**2).sum(axis=1).sum()/1332)\n",
        "MSE8 = np.sqrt(((y-y_h8)**2).sum(axis=1).sum()/1332)\n",
        "MSE9 = np.sqrt(((y-y_h9)**2).sum(axis=1).sum()/1332)\n"
      ],
      "metadata": {
        "id": "9fMZyVI0yTRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(MSE1)\n",
        "print(MSE2)\n",
        "print(MSE3)\n",
        "print(MSE4)\n",
        "print(MSE5)\n",
        "print(MSE6)\n",
        "print(MSE7)\n",
        "print(MSE8)\n",
        "print(MSE9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P62AaWY2oZms",
        "outputId": "d0327f43-3b4f-48a0-ff86-f3ac2c7d6278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6105782305391753\n",
            "0.3861275566526509\n",
            "0.36567592083543476\n",
            "0.35435097446299346\n",
            "0.3472565732985592\n",
            "0.3424009975297783\n",
            "0.33887449826949356\n",
            "0.33622249485460276\n",
            "0.3341952649313998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSA1 = np.abs(y-y_h1).sum(axis=1).sum()/1332\n",
        "MSA2 = np.abs(y-y_h2).sum(axis=1).sum()/1332\n",
        "MSA3 = np.abs(y-y_h3).sum(axis=1).sum()/1332\n",
        "MSA4 = np.abs(y-y_h4).sum(axis=1).sum()/1332\n",
        "MSA5 = np.abs(y-y_h5).sum(axis=1).sum()/1332\n",
        "MSA6 = np.abs(y-y_h6).sum(axis=1).sum()/1332\n",
        "MSA7 = np.abs(y-y_h7).sum(axis=1).sum()/1332\n",
        "MSA8 = np.abs(y-y_h8).sum(axis=1).sum()/1332\n",
        "MSA9 = np.abs(y-y_h9).sum(axis=1).sum()/1332\n",
        "print(MSA1)\n",
        "print(MSA2)\n",
        "print(MSA3)\n",
        "print(MSA4)\n",
        "print(MSA5)\n",
        "print(MSA6)\n",
        "print(MSA7)\n",
        "print(MSA8)\n",
        "print(MSA9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYqjnE9Znha1",
        "outputId": "5f183b16-0c25-4756-a05a-f1d797e982d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8184476163552163\n",
            "0.5488638027180217\n",
            "0.5184201200979199\n",
            "0.5006606181499849\n",
            "0.48949268836570603\n",
            "0.4819822237769784\n",
            "0.4767399016210116\n",
            "0.473016565981812\n",
            "0.47033820336062465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te=data['temp']\n",
        "spreadx= [None] * 1332\n",
        "for i in range(0,1331):\n",
        "  spreadx[i]= (np.abs(te[i+1]-te[i]))/2\n",
        "spreadx[1331]=spreadx[1330]\n",
        "hu=data['humidity']\n",
        "spreadm= [None] * 1332\n",
        "for i in range(0,1331):\n",
        "  spreadm[i]= (np.abs(hu[i+1]-hu[i]))/2\n",
        "spreadm[1331]=spreadm[1330]"
      ],
      "metadata": {
        "id": "C_ceF91nKOSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "CWohIvBoKUfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = data['day_power']\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, target,\n",
        "                                                      test_size=0.2,\n",
        "                                                      random_state=83,\n",
        "                                                      shuffle=True,\n",
        "                                                      )"
      ],
      "metadata": {
        "id": "j5NkLcs92fKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=x_train\n",
        "data_test=x_test"
      ],
      "metadata": {
        "id": "7PBUz23z4Ng1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdsGn-_BKdEd"
      },
      "outputs": [],
      "source": [
        "def gpbdl1(data):\n",
        " te=data['temp']\n",
        " spread= [None] * 1065\n",
        " for i in range(0,1065):\n",
        "    spread[i]= spreadx[te.index[i]]\n",
        " x1= te-spread\n",
        " x2= te+spread\n",
        " xdf=pd.DataFrame({'a':x1,'b':te,'c':x2})\n",
        " xa=xdf[xdf['a']< 0]\n",
        " xdf.loc[xa.index,'a']=0\n",
        " x=xdf.to_numpy()\n",
        "\n",
        " hu=data['humidity']\n",
        " spreadm2= [None] * 1065\n",
        " for i in range(0,1065):\n",
        "  spreadm2[i]= spreadm[hu.index[i]]\n",
        " m1= hu-spreadm2\n",
        " m2= hu+spreadm2\n",
        " mdf=pd.DataFrame({'a':m1,'b':hu,'c':m2})\n",
        " ma=mdf[mdf['a']< 0]\n",
        " mdf.loc[ma.index,'a']=0\n",
        " m=mdf.to_numpy()\n",
        "\n",
        " power=data['day_power']\n",
        " ydf=pd.DataFrame({'a':power,'b':power,'c':power})\n",
        " y= ydf.to_numpy()\n",
        "\n",
        " cl=data['sky_cover']\n",
        " w1= cl-1\n",
        " w2= cl+1\n",
        " wdf=pd.DataFrame({'a':w1,'b':cl,'c':w2})\n",
        " wa=wdf[wdf['a']< 1]\n",
        " wdf.loc[wa.index,'a']=1\n",
        " wc=wdf[wdf['c']> 8]\n",
        " wdf.loc[wc.index,'c']=8\n",
        " w=wdf.to_numpy()\n",
        " xw=x*w\n",
        "\n",
        " X_l = []\n",
        " X_m = []\n",
        " X_r = []\n",
        "\n",
        " M_l = []\n",
        " M_m = []\n",
        " M_r = []\n",
        "\n",
        " Y_l = []\n",
        " Y_m = []\n",
        " Y_r = []\n",
        "\n",
        " W_l = []\n",
        " W_m = []\n",
        " W_r = []\n",
        "\n",
        " XW_l = []\n",
        " XW_m = []\n",
        " XW_r = []\n",
        " for i in range(len(data)):\n",
        "    X_l.append(x[i][0])\n",
        "    X_m.append(x[i][1])\n",
        "    X_r.append(x[i][2])\n",
        " for i in range(len(data)):\n",
        "    M_l.append(m[i][0])\n",
        "    M_m.append(m[i][1])\n",
        "    M_r.append(m[i][2])\n",
        "\n",
        " for i in range(len(data)):\n",
        "    Y_l.append(y[i][0])\n",
        "    Y_m.append(y[i][1])\n",
        "    Y_r.append(y[i][2])\n",
        "\n",
        " for i in range(len(data)):\n",
        "    W_l.append(w[i][0])\n",
        "    W_m.append(w[i][1])\n",
        "    W_r.append(w[i][2])\n",
        "\n",
        " for i in range(len(data)):\n",
        "    XW_l.append(xw[i][0])\n",
        "    XW_m.append(xw[i][1])\n",
        "    XW_r.append(xw[i][2])\n",
        "\n",
        " ep = 800\n",
        " x_train = torch.FloatTensor([X_l])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([M_l])\n",
        " y_train = y_train.T\n",
        " Weight_l = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_l = torch.zeros(1, requires_grad=True)\n",
        " w_l=torch.zeros((9,1))\n",
        " b_l=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i]= Weight_l\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        "\n",
        " x_train = torch.FloatTensor([X_m])\n",
        " x_train = x_train.T\n",
        " x_train.shape\n",
        " y_train = torch.FloatTensor([M_m]) # M\n",
        " y_train = y_train.T\n",
        " Weight_m = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_m = torch.zeros(1, requires_grad=True)\n",
        " w_m=torch.zeros((9,1))\n",
        " b_m=torch.zeros((9,1))\n",
        " i=0\n",
        " optimizer = optim.Adagrad([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i]= Weight_m\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        " x_train = torch.FloatTensor([X_r])\n",
        " x_train = x_train.T\n",
        " x_train.shape\n",
        " y_train = torch.FloatTensor([M_r]) # M\n",
        " y_train = y_train.T\n",
        " Weight_r = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_r = torch.zeros(1, requires_grad=True)\n",
        " w_r=torch.zeros((9,1))\n",
        " b_r=torch.zeros((9,1))\n",
        " i=0\n",
        " optimizer = optim.Adagrad([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_r[i]= Weight_r\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        " w1=(w_l + w_m + w_r)/ 3\n",
        " b1=(b_l + b_m + b_r)/ 3\n",
        "\n",
        " x_train = torch.FloatTensor([X_l,W_l,XW_l,M_l])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([Y_l])\n",
        " y_train = y_train.T\n",
        " Weight_l = torch.zeros((4,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_l = torch.zeros(1, requires_grad=True)\n",
        " w_l=torch.zeros((9,4))\n",
        " b_l=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i][0]= Weight_l[0]\n",
        "      w_l[i][1]= Weight_l[1]\n",
        "      w_l[i][2]= Weight_l[2]\n",
        "      w_l[i][3]= Weight_l[3]\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        " x_train = torch.FloatTensor([X_m,W_m,XW_m,M_m])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([Y_m])\n",
        " y_train = y_train.T\n",
        " Weight_m = torch.zeros((4,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_m = torch.zeros(1, requires_grad=True)\n",
        " w_m=torch.zeros((9,4))\n",
        " b_m=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i][0]= Weight_m[0]\n",
        "      w_m[i][1]= Weight_m[1]\n",
        "      w_m[i][2]= Weight_m[2]\n",
        "      w_m[i][3]= Weight_m[3]\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        " x_train = torch.FloatTensor([X_r,W_r,XW_r,M_r])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([Y_r])\n",
        " y_train = y_train.T\n",
        " Weight_r = torch.zeros((4,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_r = torch.zeros(1, requires_grad=True)\n",
        " w_r=torch.zeros((9,4))\n",
        " b_r=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_r[i][0]= Weight_r[0]\n",
        "      w_r[i][1]= Weight_r[1]\n",
        "      w_r[i][2]= Weight_r[2]\n",
        "      w_r[i][3]= Weight_r[3]\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        "\n",
        " w2=(w_l + w_m + w_r)/ 3\n",
        " b2=(b_l + b_m + b_r)/ 3\n",
        "\n",
        " x_train = torch.FloatTensor([X_l])\n",
        " x_train = x_train.T\n",
        " y_train = torch.FloatTensor([Y_l])\n",
        " y_train = y_train.T\n",
        " Weight_l = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_l = torch.zeros(1, requires_grad=True)\n",
        " w_l=torch.zeros((9,1))\n",
        " b_l=torch.zeros((9,1))\n",
        " i=0\n",
        "  # optimizer 설정\n",
        " optimizer = optim.Adagrad([Weight_l, Bias_l], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " nb_epochs = ep  # epoch\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_l) + Bias_l\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_l[i]= Weight_l\n",
        "      b_l[i]= Bias_l\n",
        "      i=i+1\n",
        "\n",
        "\n",
        " x_train = torch.FloatTensor([X_m])\n",
        " x_train = x_train.T\n",
        " x_train.shape\n",
        " y_train = torch.FloatTensor([Y_m])\n",
        " y_train = y_train.T\n",
        " Weight_m = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_m = torch.zeros(1, requires_grad=True)\n",
        " w_m=torch.zeros((9,1))\n",
        " b_m=torch.zeros((9,1))\n",
        " i=0\n",
        " optimizer = optim.Adagrad([Weight_m, Bias_m], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_m) + Bias_m\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_m[i]= Weight_m\n",
        "      b_m[i]= Bias_m\n",
        "      i=i+1\n",
        "\n",
        " x_train = torch.FloatTensor([X_r])\n",
        " x_train = x_train.T\n",
        " x_train.shape\n",
        " y_train = torch.FloatTensor([Y_r])\n",
        " y_train = y_train.T\n",
        " Weight_r = torch.zeros((1,1), requires_grad=True)  # 가중치 초기화\n",
        " Bias_r = torch.zeros(1, requires_grad=True)\n",
        " w_r=torch.zeros((9,1))\n",
        " b_r=torch.zeros((9,1))\n",
        " i=0\n",
        " optimizer = optim.Adagrad([Weight_r, Bias_r], lr=0.01)  # Adam, lr - 0.01고정\n",
        "\n",
        " for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(X) 계산\n",
        "    hypothesis = x_train.matmul(Weight_r) + Bias_r\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 ==0:\n",
        "      w_r[i]= Weight_r\n",
        "      b_r[i]= Bias_r\n",
        "      i=i+1\n",
        "\n",
        " w3=(w_l + w_m + w_r)/ 3\n",
        " b3=(b_l + b_m + b_r)/ 3\n",
        " return w1,b1,w2,b2,w3,b3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "av=gpbdl1(data)\n",
        "av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSWVeL1Ozdd8",
        "outputId": "e48467c9-bb94-4c8c-be35-d31fd941a6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0100],\n",
              "         [0.1668],\n",
              "         [0.2255],\n",
              "         [0.2628],\n",
              "         [0.2886],\n",
              "         [0.3067],\n",
              "         [0.3194],\n",
              "         [0.3280],\n",
              "         [0.3334]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0100],\n",
              "         [0.1692],\n",
              "         [0.2312],\n",
              "         [0.2729],\n",
              "         [0.3037],\n",
              "         [0.3275],\n",
              "         [0.3465],\n",
              "         [0.3618],\n",
              "         [0.3745]], grad_fn=<DivBackward0>),\n",
              " tensor([[ 0.0100,  0.0100,  0.0100,  0.0100],\n",
              "         [ 0.1028,  0.0146,  0.0769, -0.0151],\n",
              "         [ 0.1462, -0.0029,  0.1009, -0.0541],\n",
              "         [ 0.1772, -0.0149,  0.1152, -0.0838],\n",
              "         [ 0.2007, -0.0232,  0.1235, -0.1083],\n",
              "         [ 0.2193, -0.0291,  0.1279, -0.1296],\n",
              "         [ 0.2344, -0.0332,  0.1297, -0.1489],\n",
              "         [ 0.2471, -0.0360,  0.1298, -0.1668],\n",
              "         [ 0.2580, -0.0379,  0.1288, -0.1837]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0100],\n",
              "         [0.0647],\n",
              "         [0.0906],\n",
              "         [0.1147],\n",
              "         [0.1368],\n",
              "         [0.1570],\n",
              "         [0.1757],\n",
              "         [0.1928],\n",
              "         [0.2087]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0100],\n",
              "         [0.1566],\n",
              "         [0.2040],\n",
              "         [0.2319],\n",
              "         [0.2509],\n",
              "         [0.2656],\n",
              "         [0.2779],\n",
              "         [0.2889],\n",
              "         [0.2992]], grad_fn=<DivBackward0>),\n",
              " tensor([[0.0100],\n",
              "         [0.1508],\n",
              "         [0.1888],\n",
              "         [0.2047],\n",
              "         [0.2104],\n",
              "         [0.2108],\n",
              "         [0.2086],\n",
              "         [0.2051],\n",
              "         [0.2010]], grad_fn=<DivBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " te=data['temp']\n",
        " spread= [None] * 1065\n",
        " for i in range(0,1065):\n",
        "    spread[i]= spreadx[te.index[i]]\n",
        " x1= te-spread\n",
        " x2= te+spread\n",
        " xdf=pd.DataFrame({'a':x1,'b':te,'c':x2})\n",
        " xa=xdf[xdf['a']< 0]\n",
        " xdf.loc[xa.index,'a']=0\n",
        " x=xdf.to_numpy()\n",
        "\n",
        " hu=data['humidity']\n",
        " spreadm2= [None] * 1065\n",
        " for i in range(0,1065):\n",
        "  spreadm2[i]= spreadm[hu.index[i]]\n",
        " m1= hu-spreadm2\n",
        " m2= hu+spreadm2\n",
        " mdf=pd.DataFrame({'a':m1,'b':hu,'c':m2})\n",
        " ma=mdf[mdf['a']< 0]\n",
        " mdf.loc[ma.index,'a']=0\n",
        " m=mdf.to_numpy()\n",
        "\n",
        " power=data['day_power']\n",
        " ydf=pd.DataFrame({'a':power,'b':power,'c':power})\n",
        " y= ydf.to_numpy()\n",
        "\n",
        " cl=data['sky_cover']\n",
        " w1= cl-1\n",
        " w2= cl+1\n",
        " wdf=pd.DataFrame({'a':w1,'b':cl,'c':w2})\n",
        " wa=wdf[wdf['a']< 1]\n",
        " wdf.loc[wa.index,'a']=1\n",
        " wc=wdf[wdf['c']> 8]\n",
        " wdf.loc[wc.index,'c']=8\n",
        " w_v=wdf.to_numpy()\n",
        " xw_v=x*w_v"
      ],
      "metadata": {
        "id": "OElA2N5bLAXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_h1=0.2087+0.2580*x-0.0379*w_v+0.1288*xw_v-0.1837*m\n",
        "TSS = ((y-y.mean())**2).sum(axis=1).sum()\n",
        "SSR1 = ((y_h1-y.mean())**2).sum(axis=1).sum()\n",
        "SSE1 = ((y-y_h1)**2).sum(axis=1).sum()\n",
        "R2_1 = 1 - SSE1 / TSS\n",
        "print(R2_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx8_bia86f9U",
        "outputId": "c041c087-b126-476c-c7c4-35623d833a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4670304712500326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " te=data_test['temp']\n",
        " spread= [None] * 267\n",
        " for i in range(0,267):\n",
        "    spread[i]= spreadx[te.index[i]]\n",
        " x1= te-spread\n",
        " x2= te+spread\n",
        " xdf=pd.DataFrame({'a':x1,'b':te,'c':x2})\n",
        " xa=xdf[xdf['a']< 0]\n",
        " xdf.loc[xa.index,'a']=0\n",
        " x=xdf.to_numpy()\n",
        "\n",
        " hu=data_test['humidity']\n",
        " spreadm2= [None] * 267\n",
        " for i in range(0,267):\n",
        "  spreadm2[i]= spreadm[hu.index[i]]\n",
        " m1= hu-spreadm2\n",
        " m2= hu+spreadm2\n",
        " mdf=pd.DataFrame({'a':m1,'b':hu,'c':m2})\n",
        " ma=mdf[mdf['a']< 0]\n",
        " mdf.loc[ma.index,'a']=0\n",
        " m=mdf.to_numpy()\n",
        "\n",
        " power=data_test['day_power']\n",
        " ydf=pd.DataFrame({'a':power,'b':power,'c':power})\n",
        " y= ydf.to_numpy()\n",
        "\n",
        " cl=data_test['sky_cover']\n",
        " w1= cl-1\n",
        " w2= cl+1\n",
        " wdf=pd.DataFrame({'a':w1,'b':cl,'c':w2})\n",
        " wa=wdf[wdf['a']< 1]\n",
        " wdf.loc[wa.index,'a']=1\n",
        " wc=wdf[wdf['c']> 8]\n",
        " wdf.loc[wc.index,'c']=8\n",
        " w_v=wdf.to_numpy()\n",
        " xw_v=x*w_v"
      ],
      "metadata": {
        "id": "SbE5MMib-zlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_h1=0.2087+0.2580*x-0.0379*w_v+0.1288*xw_v-0.1837*m\n",
        "TSS = ((y-y.mean())**2).sum(axis=1).sum()\n",
        "SSR1 = ((y_h1-y.mean())**2).sum(axis=1).sum()\n",
        "SSE1 = ((y-y_h1)**2).sum(axis=1).sum()\n",
        "R2_1 = 1 - SSE1 / TSS\n",
        "print(R2_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a3aa35-b336-461f-e270-63044d6af970",
        "id": "XqavbejZ_rqY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.47655295309538925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l8JVVLbSXpOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=[None]*5000\n",
        "c_b1=[None]*5000\n",
        "b_b1=[None]*5000\n",
        "cp_b1=[None]*5000\n",
        "\n",
        "a_b2=[None]*5000\n",
        "c_b2=[None]*5000\n",
        "b_b2=[None]*5000\n",
        "cp_b2=[None]*5000\n",
        "a_b3=[None]*5000\n",
        "c_b3=[None]*5000\n",
        "b_b3=[None]*5000\n",
        "cp_b3=[None]*5000\n",
        "a_b4=[None]*5000\n",
        "c_b4=[None]*5000\n",
        "b_b4=[None]*5000\n",
        "cp_b4=[None]*5000\n",
        "a_b5=[None]*5000\n",
        "c_b5=[None]*5000\n",
        "b_b5=[None]*5000\n",
        "cp_b5=[None]*5000\n",
        "a_b6=[None]*5000\n",
        "c_b6=[None]*5000\n",
        "b_b6=[None]*5000\n",
        "cp_b6=[None]*5000\n",
        "a_b7=[None]*5000\n",
        "c_b7=[None]*5000\n",
        "b_b7=[None]*5000\n",
        "cp_b7=[None]*5000\n",
        "a_b8=[None]*5000\n",
        "c_b8=[None]*5000\n",
        "b_b8=[None]*5000\n",
        "cp_b8=[None]*5000\n",
        "a_b9=[None]*5000\n",
        "c_b9=[None]*5000\n",
        "b_b9=[None]*5000\n",
        "cp_b9=[None]*5000\n",
        "a_b10=[None]*5000\n",
        "c_b10=[None]*5000\n",
        "b_b10=[None]*5000\n",
        "cp_b10=[None]*5000\n",
        "a_b11=[None]*5000\n",
        "c_b11=[None]*5000\n",
        "b_b11=[None]*5000\n",
        "cp_b11=[None]*5000\n",
        "bi1=[None]*5000\n",
        "bi2=[None]*5000\n",
        "bi3=[None]*5000\n",
        "bi4=[None]*5000\n",
        "bi5=[None]*5000\n",
        "bi6=[None]*5000\n",
        "bi7=[None]*5000\n",
        "bi8=[None]*5000\n",
        "bi9=[None]*5000\n",
        "bi10=[None]*5000\n",
        "bi11=[None]*5000\n",
        "w1=[None]*5000\n",
        "w2=[None]*5000\n",
        "w3=[None]*5000\n",
        "w4=[None]*5000\n",
        "w5=[None]*5000\n",
        "w6=[None]*5000\n",
        "w7=[None]*5000\n",
        "w8=[None]*5000\n",
        "w9=[None]*5000\n",
        "w10=[None]*5000\n",
        "w11=[None]*5000\n",
        "xw1=[None]*5000\n",
        "xw2=[None]*5000\n",
        "xw3=[None]*5000\n",
        "xw4=[None]*5000\n",
        "xw5=[None]*5000\n",
        "xw6=[None]*5000\n",
        "xw7=[None]*5000\n",
        "xw8=[None]*5000\n",
        "xw9=[None]*5000\n",
        "xw10=[None]*5000\n",
        "xw11=[None]*5000\n",
        "fbi1=[None]*5000\n",
        "fbi2=[None]*5000\n",
        "fbi3=[None]*5000\n",
        "fbi4=[None]*5000\n",
        "fbi5=[None]*5000\n",
        "fbi6=[None]*5000\n",
        "fbi7=[None]*5000\n",
        "fbi8=[None]*5000\n",
        "fbi9=[None]*5000\n",
        "\n",
        "sbi1=[None]*5000\n",
        "sbi2=[None]*5000\n",
        "sbi3=[None]*5000\n",
        "sbi4=[None]*5000\n",
        "sbi5=[None]*5000\n",
        "sbi6=[None]*5000\n",
        "sbi7=[None]*5000\n",
        "sbi8=[None]*5000\n",
        "sbi9=[None]*5000"
      ],
      "metadata": {
        "id": "lEj5cBcqexeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "lDS-_YSOXpWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#부트스트랩 표본\n",
        "for i in tqdm(range(0,5000)):\n",
        "  new_data=data.sample(n=1065,replace=True,random_state=i)\n",
        "  parameters=gpbdl1(new_data)\n",
        "  a_b1[i]= parameters[0][0].detach()\n",
        "  c_b1[i]= parameters[2][0][0].detach()\n",
        "  b_b1[i]= parameters[2][0][3].detach()\n",
        "  cp_b1[i]= parameters[4][0].detach()\n",
        "  a_b2[i]= parameters[0][1].detach()\n",
        "  c_b2[i]= parameters[2][1][0].detach()\n",
        "  b_b2[i]= parameters[2][1][3].detach()\n",
        "  cp_b2[i]= parameters[4][1].detach()\n",
        "  a_b3[i]= parameters[0][2].detach()\n",
        "  c_b3[i]= parameters[2][2][0].detach()\n",
        "  b_b3[i]= parameters[2][2][3].detach()\n",
        "  cp_b3[i]= parameters[4][2].detach()\n",
        "  a_b4[i]= parameters[0][3].detach()\n",
        "  c_b4[i]= parameters[2][3][0].detach()\n",
        "  b_b4[i]= parameters[2][3][3].detach()\n",
        "  cp_b4[i]= parameters[4][3].detach()\n",
        "  a_b5[i]= parameters[0][4].detach()\n",
        "  c_b5[i]= parameters[2][4][0].detach()\n",
        "  b_b5[i]= parameters[2][4][3].detach()\n",
        "  cp_b5[i]= parameters[4][4].detach()\n",
        "  a_b6[i]= parameters[0][5].detach()\n",
        "  c_b6[i]= parameters[2][5][0].detach()\n",
        "  b_b6[i]= parameters[2][5][3].detach()\n",
        "  cp_b6[i]= parameters[4][5].detach()\n",
        "  a_b7[i]= parameters[0][6].detach()\n",
        "  c_b7[i]= parameters[2][6][0].detach()\n",
        "  b_b7[i]= parameters[2][6][3].detach()\n",
        "  cp_b7[i]= parameters[4][6].detach()\n",
        "  a_b8[i]= parameters[0][7].detach()\n",
        "  c_b8[i]= parameters[2][7][0].detach()\n",
        "  b_b8[i]= parameters[2][7][3].detach()\n",
        "  cp_b8[i]= parameters[4][7].detach()\n",
        "  a_b9[i]= parameters[0][8].detach()\n",
        "  c_b9[i]= parameters[2][8][0].detach()\n",
        "  b_b9[i]= parameters[2][8][3].detach()\n",
        "  cp_b9[i]= parameters[4][8].detach()\n",
        "  bi1[i]=parameters[3][0].detach()\n",
        "  bi2[i]=parameters[3][1].detach()\n",
        "  bi3[i]=parameters[3][2].detach()\n",
        "  bi4[i]=parameters[3][3].detach()\n",
        "  bi5[i]=parameters[3][4].detach()\n",
        "  bi6[i]=parameters[3][5].detach()\n",
        "  bi7[i]=parameters[3][6].detach()\n",
        "  bi8[i]=parameters[3][7].detach()\n",
        "  bi9[i]=parameters[3][8].detach()\n",
        "  w1[i]=parameters[2][0][1].detach()\n",
        "  w2[i]=parameters[2][1][1].detach()\n",
        "  w3[i]=parameters[2][2][1].detach()\n",
        "  w4[i]=parameters[2][3][1].detach()\n",
        "  w5[i]=parameters[2][4][1].detach()\n",
        "  w6[i]=parameters[2][5][1].detach()\n",
        "  w7[i]=parameters[2][6][1].detach()\n",
        "  w8[i]=parameters[2][7][1].detach()\n",
        "  w9[i]=parameters[2][8][1].detach()\n",
        "  xw1[i]=parameters[2][0][2].detach()\n",
        "  xw2[i]=parameters[2][1][2].detach()\n",
        "  xw3[i]=parameters[2][2][2].detach()\n",
        "  xw4[i]=parameters[2][3][2].detach()\n",
        "  xw5[i]=parameters[2][4][2].detach()\n",
        "  xw6[i]=parameters[2][5][2].detach()\n",
        "  xw7[i]=parameters[2][6][2].detach()\n",
        "  xw8[i]=parameters[2][7][2].detach()\n",
        "  xw9[i]=parameters[2][8][2].detach()\n",
        "\n",
        "  fbi1[i]=parameters[1][0].detach()\n",
        "  fbi2[i]=parameters[1][1].detach()\n",
        "  fbi3[i]=parameters[1][2].detach()\n",
        "  fbi4[i]=parameters[1][3].detach()\n",
        "  fbi5[i]=parameters[1][4].detach()\n",
        "  fbi6[i]=parameters[1][5].detach()\n",
        "  fbi7[i]=parameters[1][6].detach()\n",
        "  fbi8[i]=parameters[1][7].detach()\n",
        "  fbi9[i]=parameters[1][8].detach()\n",
        "\n",
        "  sbi1[i]=parameters[5][0].detach()\n",
        "  sbi2[i]=parameters[5][1].detach()\n",
        "  sbi3[i]=parameters[5][2].detach()\n",
        "  sbi4[i]=parameters[5][3].detach()\n",
        "  sbi5[i]=parameters[5][4].detach()\n",
        "  sbi6[i]=parameters[5][5].detach()\n",
        "  sbi7[i]=parameters[5][6].detach()\n",
        "  sbi8[i]=parameters[5][7].detach()\n",
        "  sbi9[i]=parameters[5][8].detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb0d75d-97f8-43cd-b7b3-e4832eb2baeb",
        "id": "dEk1jFZ6e1ND"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [2:55:05<00:00,  2.10s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('a_b1',a_b1)\n",
        "np.save('b_b1',b_b1)\n",
        "np.save('c_b1',c_b1)\n",
        "np.save('cp_b1',cp_b1)\n",
        "np.save('a_b2',a_b2)\n",
        "np.save('b_b2',b_b2)\n",
        "np.save('c_b2',c_b2)\n",
        "np.save('cp_b2',cp_b2)\n",
        "np.save('a_b3',a_b3)\n",
        "np.save('b_b3',b_b3)\n",
        "np.save('c_b3',c_b3)\n",
        "np.save('cp_b3',cp_b3)\n",
        "np.save('a_b4',a_b4)\n",
        "np.save('b_b4',b_b4)\n",
        "np.save('c_b4',c_b4)\n",
        "np.save('cp_b4',cp_b4)\n",
        "np.save('a_b5',a_b5)\n",
        "np.save('b_b5',b_b5)\n",
        "np.save('c_b5',c_b5)\n",
        "np.save('cp_b5',cp_b5)\n",
        "np.save('a_b6',a_b6)\n",
        "np.save('b_b6',b_b6)\n",
        "np.save('c_b6',c_b6)\n",
        "np.save('cp_b6',cp_b6)\n",
        "np.save('a_b7',a_b7)\n",
        "np.save('b_b7',b_b7)\n",
        "np.save('c_b7',c_b7)\n",
        "np.save('cp_b7',cp_b7)\n",
        "np.save('a_b8',a_b8)\n",
        "np.save('b_b8',b_b8)\n",
        "np.save('c_b8',c_b8)\n",
        "np.save('cp_b8',cp_b8)\n",
        "np.save('a_b9',a_b9)\n",
        "np.save('b_b9',b_b9)\n",
        "np.save('c_b9',c_b9)\n",
        "np.save('cp_b9',cp_b9)\n",
        "np.save('bi1',bi1)\n",
        "np.save('bi2',bi2)\n",
        "np.save('bi3',bi3)\n",
        "np.save('bi4',bi4)\n",
        "np.save('bi5',bi5)\n",
        "np.save('bi6',bi6)\n",
        "np.save('bi7',bi7)\n",
        "np.save('bi8',bi8)\n",
        "np.save('bi9',bi9)\n",
        "np.save('w1',w1)\n",
        "np.save('w2',w2)\n",
        "np.save('w3',w3)\n",
        "np.save('w4',w4)\n",
        "np.save('w5',w5)\n",
        "np.save('w6',w6)\n",
        "np.save('w7',w7)\n",
        "np.save('w8',w8)\n",
        "np.save('w9',w9)\n",
        "np.save('xw1',xw1)\n",
        "np.save('xw2',xw2)\n",
        "np.save('xw3',xw3)\n",
        "np.save('xw4',xw4)\n",
        "np.save('xw5',xw5)\n",
        "np.save('xw6',xw6)\n",
        "np.save('xw7',xw7)\n",
        "np.save('xw8',xw8)\n",
        "np.save('xw9',xw9)\n",
        "\n",
        "np.save('fbi1',fbi1)\n",
        "np.save('fbi2',fbi2)\n",
        "np.save('fbi3',fbi3)\n",
        "np.save('fbi4',fbi4)\n",
        "np.save('fbi5',fbi5)\n",
        "np.save('fbi6',fbi6)\n",
        "np.save('fbi7',fbi7)\n",
        "np.save('fbi8',fbi8)\n",
        "np.save('fbi9',fbi9)\n",
        "\n",
        "np.save('sbi1',sbi1)\n",
        "np.save('sbi2',sbi2)\n",
        "np.save('sbi3',sbi3)\n",
        "np.save('sbi4',sbi4)\n",
        "np.save('sbi5',sbi5)\n",
        "np.save('sbi6',sbi6)\n",
        "np.save('sbi7',sbi7)\n",
        "np.save('sbi8',sbi8)\n",
        "np.save('sbi9',sbi9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b2f0e4-10ac-4eb6-f474-869f323f1c13",
        "id": "zg2cOzxGADbu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:521: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  arr = np.asanyarray(arr)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=np.load('a_b1.npy',allow_pickle=True)\n",
        "b_b1=np.load('b_b1.npy',allow_pickle=True)\n",
        "c_b1=np.load('c_b1.npy',allow_pickle=True)\n",
        "cp_b1=np.load('cp_b1.npy',allow_pickle=True)\n",
        "ab_b1=a_b1*b_b1\n",
        "a_b2=np.load('a_b2.npy',allow_pickle=True)\n",
        "b_b2=np.load('b_b2.npy',allow_pickle=True)\n",
        "c_b2=np.load('c_b2.npy',allow_pickle=True)\n",
        "cp_b2=np.load('cp_b2.npy',allow_pickle=True)\n",
        "ab_b2=a_b2*b_b2\n",
        "a_b3=np.load('a_b3.npy',allow_pickle=True)\n",
        "b_b3=np.load('b_b3.npy',allow_pickle=True)\n",
        "c_b3=np.load('c_b3.npy',allow_pickle=True)\n",
        "cp_b3=np.load('cp_b3.npy',allow_pickle=True)\n",
        "ab_b3=a_b3*b_b3\n",
        "a_b4=np.load('a_b4.npy',allow_pickle=True)\n",
        "b_b4=np.load('b_b4.npy',allow_pickle=True)\n",
        "c_b4=np.load('c_b4.npy',allow_pickle=True)\n",
        "cp_b4=np.load('cp_b4.npy',allow_pickle=True)\n",
        "ab_b4=a_b4*b_b4\n",
        "a_b5=np.load('a_b5.npy',allow_pickle=True)\n",
        "b_b5=np.load('b_b5.npy',allow_pickle=True)\n",
        "c_b5=np.load('c_b5.npy',allow_pickle=True)\n",
        "cp_b5=np.load('cp_b5.npy',allow_pickle=True)\n",
        "ab_b5=a_b5*b_b5\n",
        "a_b6=np.load('a_b6.npy',allow_pickle=True)\n",
        "b_b6=np.load('b_b6.npy',allow_pickle=True)\n",
        "c_b6=np.load('c_b6.npy',allow_pickle=True)\n",
        "cp_b6=np.load('cp_b6.npy',allow_pickle=True)\n",
        "ab_b6=a_b6*b_b6\n",
        "a_b7=np.load('a_b7.npy',allow_pickle=True)\n",
        "b_b7=np.load('b_b7.npy',allow_pickle=True)\n",
        "c_b7=np.load('c_b7.npy',allow_pickle=True)\n",
        "cp_b7=np.load('cp_b7.npy',allow_pickle=True)\n",
        "ab_b7=a_b7*b_b7\n",
        "a_b8=np.load('a_b8.npy',allow_pickle=True)\n",
        "b_b8=np.load('b_b8.npy',allow_pickle=True)\n",
        "c_b8=np.load('c_b8.npy',allow_pickle=True)\n",
        "cp_b8=np.load('cp_b8.npy',allow_pickle=True)\n",
        "ab_b8=a_b8*b_b8\n",
        "a_b9=np.load('a_b9.npy',allow_pickle=True)\n",
        "b_b9=np.load('b_b9.npy',allow_pickle=True)\n",
        "c_b9=np.load('c_b9.npy',allow_pickle=True)\n",
        "cp_b9=np.load('cp_b9.npy',allow_pickle=True)\n",
        "ab_b9=a_b9*b_b9\n",
        "bi1=np.load('bi1.npy',allow_pickle=True)\n",
        "bi2=np.load('bi2.npy',allow_pickle=True)\n",
        "bi3=np.load('bi3.npy',allow_pickle=True)\n",
        "bi4=np.load('bi4.npy',allow_pickle=True)\n",
        "bi5=np.load('bi5.npy',allow_pickle=True)\n",
        "bi6=np.load('bi6.npy',allow_pickle=True)\n",
        "bi7=np.load('bi7.npy',allow_pickle=True)\n",
        "bi8=np.load('bi8.npy',allow_pickle=True)\n",
        "bi9=np.load('bi9.npy',allow_pickle=True)\n",
        "w1=np.load('w1.npy',allow_pickle=True)\n",
        "w2=np.load('w2.npy',allow_pickle=True)\n",
        "w3=np.load('w3.npy',allow_pickle=True)\n",
        "w4=np.load('w4.npy',allow_pickle=True)\n",
        "w5=np.load('w5.npy',allow_pickle=True)\n",
        "w6=np.load('w6.npy',allow_pickle=True)\n",
        "w7=np.load('w7.npy',allow_pickle=True)\n",
        "w8=np.load('w8.npy',allow_pickle=True)\n",
        "w9=np.load('w9.npy',allow_pickle=True)\n",
        "xw1=np.load('xw1.npy',allow_pickle=True)\n",
        "xw2=np.load('xw2.npy',allow_pickle=True)\n",
        "xw3=np.load('xw3.npy',allow_pickle=True)\n",
        "xw4=np.load('xw4.npy',allow_pickle=True)\n",
        "xw5=np.load('xw5.npy',allow_pickle=True)\n",
        "xw6=np.load('xw6.npy',allow_pickle=True)\n",
        "xw7=np.load('xw7.npy',allow_pickle=True)\n",
        "xw8=np.load('xw8.npy',allow_pickle=True)\n",
        "xw9=np.load('xw9.npy',allow_pickle=True)"
      ],
      "metadata": {
        "id": "oQ8xv2_ZGahQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1= a_b1.tolist()\n",
        "b_b1= b_b1.tolist()\n",
        "c_b1= c_b1.tolist()\n",
        "cp_b1= cp_b1.tolist()\n",
        "ab_b1= ab_b1.tolist()\n",
        "a_b2= a_b2.tolist()\n",
        "b_b2= b_b2.tolist()\n",
        "c_b2= c_b2.tolist()\n",
        "cp_b2= cp_b2.tolist()\n",
        "ab_b2= ab_b2.tolist()\n",
        "a_b3= a_b3.tolist()\n",
        "b_b3= b_b3.tolist()\n",
        "c_b3= c_b3.tolist()\n",
        "cp_b3= cp_b3.tolist()\n",
        "ab_b3= ab_b3.tolist()\n",
        "a_b4= a_b4.tolist()\n",
        "b_b4= b_b4.tolist()\n",
        "c_b4= c_b4.tolist()\n",
        "cp_b4= cp_b4.tolist()\n",
        "ab_b4= ab_b4.tolist()\n",
        "a_b5= a_b5.tolist()\n",
        "b_b5= b_b5.tolist()\n",
        "c_b5= c_b5.tolist()\n",
        "cp_b5= cp_b5.tolist()\n",
        "ab_b5= ab_b5.tolist()\n",
        "a_b6= a_b6.tolist()\n",
        "b_b6= b_b6.tolist()\n",
        "c_b6= c_b6.tolist()\n",
        "cp_b6= cp_b6.tolist()\n",
        "ab_b6= ab_b6.tolist()\n",
        "a_b7= a_b7.tolist()\n",
        "b_b7= b_b7.tolist()\n",
        "c_b7= c_b7.tolist()\n",
        "cp_b7= cp_b7.tolist()\n",
        "ab_b7= ab_b7.tolist()\n",
        "a_b8= a_b8.tolist()\n",
        "b_b8= b_b8.tolist()\n",
        "c_b8= c_b8.tolist()\n",
        "cp_b8= cp_b8.tolist()\n",
        "ab_b8= ab_b8.tolist()\n",
        "a_b9= a_b9.tolist()\n",
        "b_b9= b_b9.tolist()\n",
        "c_b9= c_b9.tolist()\n",
        "cp_b9= cp_b9.tolist()\n",
        "ab_b9= ab_b9.tolist()\n",
        "bi1=bi1.tolist()\n",
        "bi2=bi2.tolist()\n",
        "bi3=bi3.tolist()\n",
        "bi4=bi4.tolist()\n",
        "bi5=bi5.tolist()\n",
        "bi6=bi6.tolist()\n",
        "bi7=bi7.tolist()\n",
        "bi8=bi8.tolist()\n",
        "bi9=bi9.tolist()\n",
        "w1=w1.tolist()\n",
        "w2=w2.tolist()\n",
        "w3=w3.tolist()\n",
        "w4=w4.tolist()\n",
        "w5=w5.tolist()\n",
        "w6=w6.tolist()\n",
        "w7=w7.tolist()\n",
        "w8=w8.tolist()\n",
        "w9=w9.tolist()\n",
        "xw1=xw1.tolist()\n",
        "xw2=xw2.tolist()\n",
        "xw3=xw3.tolist()\n",
        "xw4=xw4.tolist()\n",
        "xw5=xw5.tolist()\n",
        "xw6=xw6.tolist()\n",
        "xw7=xw7.tolist()\n",
        "xw8=xw8.tolist()\n",
        "xw9=xw9.tolist()\n"
      ],
      "metadata": {
        "id": "yhsQ9BakGcfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_b1=np.array(a_b1)\n",
        "b_b1=np.array(b_b1)\n",
        "c_b1=np.array(c_b1)\n",
        "cp_b1=np.array(cp_b1)\n",
        "ab_b1=np.array(ab_b1)\n",
        "a_b2=np.array(a_b2)\n",
        "b_b2=np.array(b_b2)\n",
        "c_b2=np.array(c_b2)\n",
        "cp_b2=np.array(cp_b2)\n",
        "ab_b2=np.array(ab_b2)\n",
        "a_b3=np.array(a_b3)\n",
        "b_b3=np.array(b_b3)\n",
        "c_b3=np.array(c_b3)\n",
        "cp_b3=np.array(cp_b3)\n",
        "ab_b3=np.array(ab_b3)\n",
        "a_b4=np.array(a_b4)\n",
        "b_b4=np.array(b_b4)\n",
        "c_b4=np.array(c_b4)\n",
        "cp_b4=np.array(cp_b4)\n",
        "ab_b4=np.array(ab_b4)\n",
        "a_b5=np.array(a_b5)\n",
        "b_b5=np.array(b_b5)\n",
        "c_b5=np.array(c_b5)\n",
        "cp_b5=np.array(cp_b5)\n",
        "ab_b5=np.array(ab_b5)\n",
        "a_b6=np.array(a_b6)\n",
        "b_b6=np.array(b_b6)\n",
        "c_b6=np.array(c_b6)\n",
        "cp_b6=np.array(cp_b6)\n",
        "ab_b6=np.array(ab_b6)\n",
        "a_b7=np.array(a_b7)\n",
        "b_b7=np.array(b_b7)\n",
        "c_b7=np.array(c_b7)\n",
        "cp_b7=np.array(cp_b7)\n",
        "ab_b7=np.array(ab_b7)\n",
        "a_b8=np.array(a_b8)\n",
        "b_b8=np.array(b_b8)\n",
        "c_b8=np.array(c_b8)\n",
        "cp_b8=np.array(cp_b8)\n",
        "ab_b8=np.array(ab_b8)\n",
        "a_b9=np.array(a_b9)\n",
        "b_b9=np.array(b_b9)\n",
        "c_b9=np.array(c_b9)\n",
        "cp_b9=np.array(cp_b9)\n",
        "ab_b9=np.array(ab_b9)\n",
        "bi1=np.array(bi1)\n",
        "bi2=np.array(bi2)\n",
        "bi3=np.array(bi3)\n",
        "bi4=np.array(bi4)\n",
        "bi5=np.array(bi5)\n",
        "bi6=np.array(bi6)\n",
        "bi7=np.array(bi7)\n",
        "bi8=np.array(bi8)\n",
        "bi9=np.array(bi9)\n",
        "\n",
        "w1=np.array(w1)\n",
        "w2=np.array(w2)\n",
        "w3=np.array(w3)\n",
        "w4=np.array(w4)\n",
        "w5=np.array(w5)\n",
        "w6=np.array(w6)\n",
        "w7=np.array(w7)\n",
        "w8=np.array(w8)\n",
        "w9=np.array(w9)\n",
        "\n",
        "xw1=np.array(xw1)\n",
        "xw2=np.array(xw2)\n",
        "xw3=np.array(xw3)\n",
        "xw4=np.array(xw4)\n",
        "xw5=np.array(xw5)\n",
        "xw6=np.array(xw6)\n",
        "xw7=np.array(xw7)\n",
        "xw8=np.array(xw8)\n",
        "xw9=np.array(xw9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e83a74-1ff2-4879-a78e-1163d26ebc91",
        "id": "Rps1psF4Gd9X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-f725740b8c1b>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b1=np.array(a_b1)\n",
            "<ipython-input-21-f725740b8c1b>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b1=np.array(a_b1)\n",
            "<ipython-input-21-f725740b8c1b>:4: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b1=np.array(cp_b1)\n",
            "<ipython-input-21-f725740b8c1b>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b1=np.array(cp_b1)\n",
            "<ipython-input-21-f725740b8c1b>:5: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b1=np.array(ab_b1)\n",
            "<ipython-input-21-f725740b8c1b>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b1=np.array(ab_b1)\n",
            "<ipython-input-21-f725740b8c1b>:6: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b2=np.array(a_b2)\n",
            "<ipython-input-21-f725740b8c1b>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b2=np.array(a_b2)\n",
            "<ipython-input-21-f725740b8c1b>:9: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b2=np.array(cp_b2)\n",
            "<ipython-input-21-f725740b8c1b>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b2=np.array(cp_b2)\n",
            "<ipython-input-21-f725740b8c1b>:10: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b2=np.array(ab_b2)\n",
            "<ipython-input-21-f725740b8c1b>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b2=np.array(ab_b2)\n",
            "<ipython-input-21-f725740b8c1b>:11: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b3=np.array(a_b3)\n",
            "<ipython-input-21-f725740b8c1b>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b3=np.array(a_b3)\n",
            "<ipython-input-21-f725740b8c1b>:14: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b3=np.array(cp_b3)\n",
            "<ipython-input-21-f725740b8c1b>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b3=np.array(cp_b3)\n",
            "<ipython-input-21-f725740b8c1b>:15: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b3=np.array(ab_b3)\n",
            "<ipython-input-21-f725740b8c1b>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b3=np.array(ab_b3)\n",
            "<ipython-input-21-f725740b8c1b>:16: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b4=np.array(a_b4)\n",
            "<ipython-input-21-f725740b8c1b>:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b4=np.array(a_b4)\n",
            "<ipython-input-21-f725740b8c1b>:19: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b4=np.array(cp_b4)\n",
            "<ipython-input-21-f725740b8c1b>:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b4=np.array(cp_b4)\n",
            "<ipython-input-21-f725740b8c1b>:20: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b4=np.array(ab_b4)\n",
            "<ipython-input-21-f725740b8c1b>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b4=np.array(ab_b4)\n",
            "<ipython-input-21-f725740b8c1b>:21: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b5=np.array(a_b5)\n",
            "<ipython-input-21-f725740b8c1b>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b5=np.array(a_b5)\n",
            "<ipython-input-21-f725740b8c1b>:24: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b5=np.array(cp_b5)\n",
            "<ipython-input-21-f725740b8c1b>:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b5=np.array(cp_b5)\n",
            "<ipython-input-21-f725740b8c1b>:25: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b5=np.array(ab_b5)\n",
            "<ipython-input-21-f725740b8c1b>:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b5=np.array(ab_b5)\n",
            "<ipython-input-21-f725740b8c1b>:26: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b6=np.array(a_b6)\n",
            "<ipython-input-21-f725740b8c1b>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b6=np.array(a_b6)\n",
            "<ipython-input-21-f725740b8c1b>:29: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b6=np.array(cp_b6)\n",
            "<ipython-input-21-f725740b8c1b>:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b6=np.array(cp_b6)\n",
            "<ipython-input-21-f725740b8c1b>:30: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b6=np.array(ab_b6)\n",
            "<ipython-input-21-f725740b8c1b>:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b6=np.array(ab_b6)\n",
            "<ipython-input-21-f725740b8c1b>:31: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b7=np.array(a_b7)\n",
            "<ipython-input-21-f725740b8c1b>:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b7=np.array(a_b7)\n",
            "<ipython-input-21-f725740b8c1b>:34: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b7=np.array(cp_b7)\n",
            "<ipython-input-21-f725740b8c1b>:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b7=np.array(cp_b7)\n",
            "<ipython-input-21-f725740b8c1b>:35: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b7=np.array(ab_b7)\n",
            "<ipython-input-21-f725740b8c1b>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b7=np.array(ab_b7)\n",
            "<ipython-input-21-f725740b8c1b>:36: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b8=np.array(a_b8)\n",
            "<ipython-input-21-f725740b8c1b>:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b8=np.array(a_b8)\n",
            "<ipython-input-21-f725740b8c1b>:39: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b8=np.array(cp_b8)\n",
            "<ipython-input-21-f725740b8c1b>:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b8=np.array(cp_b8)\n",
            "<ipython-input-21-f725740b8c1b>:40: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b8=np.array(ab_b8)\n",
            "<ipython-input-21-f725740b8c1b>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b8=np.array(ab_b8)\n",
            "<ipython-input-21-f725740b8c1b>:41: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  a_b9=np.array(a_b9)\n",
            "<ipython-input-21-f725740b8c1b>:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  a_b9=np.array(a_b9)\n",
            "<ipython-input-21-f725740b8c1b>:44: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  cp_b9=np.array(cp_b9)\n",
            "<ipython-input-21-f725740b8c1b>:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cp_b9=np.array(cp_b9)\n",
            "<ipython-input-21-f725740b8c1b>:45: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  ab_b9=np.array(ab_b9)\n",
            "<ipython-input-21-f725740b8c1b>:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ab_b9=np.array(ab_b9)\n",
            "<ipython-input-21-f725740b8c1b>:46: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi1=np.array(bi1)\n",
            "<ipython-input-21-f725740b8c1b>:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi1=np.array(bi1)\n",
            "<ipython-input-21-f725740b8c1b>:47: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi2=np.array(bi2)\n",
            "<ipython-input-21-f725740b8c1b>:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi2=np.array(bi2)\n",
            "<ipython-input-21-f725740b8c1b>:48: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi3=np.array(bi3)\n",
            "<ipython-input-21-f725740b8c1b>:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi3=np.array(bi3)\n",
            "<ipython-input-21-f725740b8c1b>:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi4=np.array(bi4)\n",
            "<ipython-input-21-f725740b8c1b>:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi4=np.array(bi4)\n",
            "<ipython-input-21-f725740b8c1b>:50: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi5=np.array(bi5)\n",
            "<ipython-input-21-f725740b8c1b>:50: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi5=np.array(bi5)\n",
            "<ipython-input-21-f725740b8c1b>:51: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi6=np.array(bi6)\n",
            "<ipython-input-21-f725740b8c1b>:51: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi6=np.array(bi6)\n",
            "<ipython-input-21-f725740b8c1b>:52: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi7=np.array(bi7)\n",
            "<ipython-input-21-f725740b8c1b>:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi7=np.array(bi7)\n",
            "<ipython-input-21-f725740b8c1b>:53: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi8=np.array(bi8)\n",
            "<ipython-input-21-f725740b8c1b>:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi8=np.array(bi8)\n",
            "<ipython-input-21-f725740b8c1b>:54: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  bi9=np.array(bi9)\n",
            "<ipython-input-21-f725740b8c1b>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bi9=np.array(bi9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_1=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_1[i]=bi1[i].item()\n",
        "bi_2=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_2[i]=bi2[i].item()\n",
        "bi_3=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_3[i]=bi3[i].item()\n",
        "bi_4=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_4[i]=bi4[i].item()\n",
        "bi_5=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_5[i]=bi5[i].item()\n",
        "bi_6=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_6[i]=bi6[i].item()\n",
        "bi_7=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_7[i]=bi7[i].item()\n",
        "bi_8=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_8[i]=bi8[i].item()\n",
        "bi_9=[None]*5000\n",
        "for i in range(0,5000):\n",
        "  bi_9[i]=bi9[i].item()\n"
      ],
      "metadata": {
        "id": "Zxr4_-j4GfoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics"
      ],
      "metadata": {
        "id": "L5nEXaFFGhO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=[None]*9\n",
        "b=[None]*9\n",
        "bi=[None]*9\n",
        "w=[None]*9\n",
        "xw=[None]*9\n",
        "c[0]=c_b1.mean()\n",
        "b[0]=b_b1.mean()\n",
        "bi[0]=statistics.mean(bi_1)\n",
        "c[1]=c_b2.mean()\n",
        "b[1]=b_b2.mean()\n",
        "bi[1]=statistics.mean(bi_2)\n",
        "c[2]=c_b3.mean()\n",
        "b[2]=b_b3.mean()\n",
        "bi[2]=statistics.mean(bi_3)\n",
        "c[3]=c_b4.mean()\n",
        "b[3]=b_b4.mean()\n",
        "bi[3]=statistics.mean(bi_4)\n",
        "c[4]=c_b5.mean()\n",
        "b[4]=b_b5.mean()\n",
        "bi[4]=statistics.mean(bi_5)\n",
        "c[5]=c_b6.mean()\n",
        "b[5]=b_b6.mean()\n",
        "bi[5]=statistics.mean(bi_6)\n",
        "c[6]=c_b7.mean()\n",
        "b[6]=b_b7.mean()\n",
        "bi[6]=statistics.mean(bi_7)\n",
        "c[7]=c_b8.mean()\n",
        "b[7]=b_b8.mean()\n",
        "bi[7]=statistics.mean(bi_8)\n",
        "c[8]=c_b9.mean()\n",
        "b[8]=b_b9.mean()\n",
        "bi[8]=statistics.mean(bi_9)\n",
        "w[0]=w1.mean()\n",
        "w[1]=w2.mean()\n",
        "w[2]=w3.mean()\n",
        "w[3]=w4.mean()\n",
        "w[4]=w5.mean()\n",
        "w[5]=w6.mean()\n",
        "w[6]=w7.mean()\n",
        "w[7]=w8.mean()\n",
        "w[8]=w9.mean()\n",
        "\n",
        "xw[0]=xw1.mean()\n",
        "xw[1]=xw2.mean()\n",
        "xw[2]=xw3.mean()\n",
        "xw[3]=xw4.mean()\n",
        "xw[4]=xw5.mean()\n",
        "xw[5]=xw6.mean()\n",
        "xw[6]=xw7.mean()\n",
        "xw[7]=xw8.mean()\n",
        "xw[8]=xw9.mean()\n"
      ],
      "metadata": {
        "id": "guLDPxx-GiTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " te=data['temp']\n",
        " spread= [None] * 1065\n",
        " for i in range(0,1065):\n",
        "    spread[i]= spreadx[te.index[i]]\n",
        " x1= te-spread\n",
        " x2= te+spread\n",
        " xdf=pd.DataFrame({'a':x1,'b':te,'c':x2})\n",
        " xa=xdf[xdf['a']< 0]\n",
        " xdf.loc[xa.index,'a']=0\n",
        " x=xdf.to_numpy()\n",
        "\n",
        " hu=data['humidity']\n",
        " spreadm2= [None] * 1065\n",
        " for i in range(0,1065):\n",
        "  spreadm2[i]= spreadm[hu.index[i]]\n",
        " m1= hu-spreadm2\n",
        " m2= hu+spreadm2\n",
        " mdf=pd.DataFrame({'a':m1,'b':hu,'c':m2})\n",
        " ma=mdf[mdf['a']< 0]\n",
        " mdf.loc[ma.index,'a']=0\n",
        " m=mdf.to_numpy()\n",
        "\n",
        " power=data['day_power']\n",
        " ydf=pd.DataFrame({'a':power,'b':power,'c':power})\n",
        " y= ydf.to_numpy()\n",
        "\n",
        " cl=data['sky_cover']\n",
        " w1= cl-1\n",
        " w2= cl+1\n",
        " wdf=pd.DataFrame({'a':w1,'b':cl,'c':w2})\n",
        " wa=wdf[wdf['a']< 1]\n",
        " wdf.loc[wa.index,'a']=1\n",
        " wc=wdf[wdf['c']> 8]\n",
        " wdf.loc[wc.index,'c']=8\n",
        " w_v=wdf.to_numpy()\n",
        " xw_v=x*w_v"
      ],
      "metadata": {
        "id": "d8WlXeRVyvJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_h1=bi[0]+c[0]*x+b[0]*m+w[0]*w_v+xw[0]*xw_v\n",
        "y_h2=bi[1]+c[1]*x+b[1]*m+w[1]*w_v+xw[1]*xw_v\n",
        "y_h3=bi[2]+c[2]*x+b[2]*m+w[2]*w_v+xw[2]*xw_v\n",
        "y_h4=bi[3]+c[3]*x+b[3]*m+w[3]*w_v+xw[3]*xw_v\n",
        "y_h5=bi[4]+c[4]*x+b[4]*m+w[4]*w_v+xw[4]*xw_v\n",
        "y_h6=bi[5]+c[5]*x+b[5]*m+w[5]*w_v+xw[5]*xw_v\n",
        "y_h7=bi[6]+c[6]*x+b[6]*m+w[6]*w_v+xw[6]*xw_v\n",
        "y_h8=bi[7]+c[7]*x+b[7]*m+w[7]*w_v+xw[7]*xw_v\n",
        "y_h9=bi[8]+c[8]*x+b[8]*m+w[8]*w_v+xw[8]*xw_v\n"
      ],
      "metadata": {
        "id": "Ymk5gSbFGk9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TSS = ((y-y.mean())**2).sum(axis=1).sum()\n",
        "SSR1 = ((y_h1-y.mean())**2).sum(axis=1).sum()\n",
        "SSE1 = ((y-y_h1)**2).sum(axis=1).sum()\n",
        "SSR2 = ((y_h2-y.mean())**2).sum(axis=1).sum()\n",
        "SSE2 = ((y-y_h2)**2).sum(axis=1).sum()\n",
        "SSR3 = ((y_h3-y.mean())**2).sum(axis=1).sum()\n",
        "SSE3 = ((y-y_h3)**2).sum(axis=1).sum()\n",
        "SSR4 = ((y_h4-y.mean())**2).sum(axis=1).sum()\n",
        "SSE4 = ((y-y_h4)**2).sum(axis=1).sum()\n",
        "SSR5 = ((y_h5-y.mean())**2).sum(axis=1).sum()\n",
        "SSE5 = ((y-y_h5)**2).sum(axis=1).sum()\n",
        "SSR6 = ((y_h6-y.mean())**2).sum(axis=1).sum()\n",
        "SSE6 = ((y-y_h6)**2).sum(axis=1).sum()\n",
        "SSR7 = ((y_h7-y.mean())**2).sum(axis=1).sum()\n",
        "SSE7 = ((y-y_h7)**2).sum(axis=1).sum()\n",
        "SSR8 = ((y_h8-y.mean())**2).sum(axis=1).sum()\n",
        "SSE8 = ((y-y_h8)**2).sum(axis=1).sum()\n",
        "SSR9 = ((y_h9-y.mean())**2).sum(axis=1).sum()\n",
        "SSE9 = ((y-y_h9)**2).sum(axis=1).sum()\n"
      ],
      "metadata": {
        "id": "DXFIodNxGmMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R2_1 = 1 - SSE1 / TSS\n",
        "print(R2_1)\n",
        "R2_2 = 1 - SSE2 / TSS\n",
        "print(R2_2)\n",
        "R2_3 = 1 - SSE3 / TSS\n",
        "print(R2_3)\n",
        "R2_4 = 1 - SSE4 / TSS\n",
        "print(R2_4)\n",
        "R2_5 = 1 - SSE5 / TSS\n",
        "print(R2_5)\n",
        "R2_6 = 1 - SSE6 / TSS\n",
        "print(R2_6)\n",
        "R2_7 = 1 - SSE7 / TSS\n",
        "print(R2_7)\n",
        "R2_8 = 1 - SSE8 / TSS\n",
        "print(R2_8)\n",
        "R2_9 = 1 - SSE9 / TSS\n",
        "print(R2_9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9493342d-371c-4010-b5d8-39466903a2b0",
        "id": "db14APB0Gnhq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0961030637522735\n",
            "0.15888725845839158\n",
            "0.27825903576339095\n",
            "0.3438285350541638\n",
            "0.38469340257723106\n",
            "0.4130671892132949\n",
            "0.43457318509639875\n",
            "0.4519684972868543\n",
            "0.4666839580144958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " te=data_test['temp']\n",
        " spread= [None] * 267\n",
        " for i in range(0,267):\n",
        "    spread[i]= spreadx[te.index[i]]\n",
        " x1= te-spread\n",
        " x2= te+spread\n",
        " xdf=pd.DataFrame({'a':x1,'b':te,'c':x2})\n",
        " xa=xdf[xdf['a']< 0]\n",
        " xdf.loc[xa.index,'a']=0\n",
        " x=xdf.to_numpy()\n",
        "\n",
        " hu=data_test['humidity']\n",
        " spreadm2= [None] * 267\n",
        " for i in range(0,267):\n",
        "  spreadm2[i]= spreadm[hu.index[i]]\n",
        " m1= hu-spreadm2\n",
        " m2= hu+spreadm2\n",
        " mdf=pd.DataFrame({'a':m1,'b':hu,'c':m2})\n",
        " ma=mdf[mdf['a']< 0]\n",
        " mdf.loc[ma.index,'a']=0\n",
        " m=mdf.to_numpy()\n",
        "\n",
        " power=data_test['day_power']\n",
        " ydf=pd.DataFrame({'a':power,'b':power,'c':power})\n",
        " y= ydf.to_numpy()\n",
        "\n",
        " cl=data_test['sky_cover']\n",
        " w1= cl-1\n",
        " w2= cl+1\n",
        " wdf=pd.DataFrame({'a':w1,'b':cl,'c':w2})\n",
        " wa=wdf[wdf['a']< 1]\n",
        " wdf.loc[wa.index,'a']=1\n",
        " wc=wdf[wdf['c']> 8]\n",
        " wdf.loc[wc.index,'c']=8\n",
        " w_v=wdf.to_numpy()\n",
        " xw_v=x*w_v"
      ],
      "metadata": {
        "id": "3gQ3Lsgyy8lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_h1=bi[0]+c[0]*x+b[0]*m+w[0]*w_v+xw[0]*xw_v\n",
        "y_h2=bi[1]+c[1]*x+b[1]*m+w[1]*w_v+xw[1]*xw_v\n",
        "y_h3=bi[2]+c[2]*x+b[2]*m+w[2]*w_v+xw[2]*xw_v\n",
        "y_h4=bi[3]+c[3]*x+b[3]*m+w[3]*w_v+xw[3]*xw_v\n",
        "y_h5=bi[4]+c[4]*x+b[4]*m+w[4]*w_v+xw[4]*xw_v\n",
        "y_h6=bi[5]+c[5]*x+b[5]*m+w[5]*w_v+xw[5]*xw_v\n",
        "y_h7=bi[6]+c[6]*x+b[6]*m+w[6]*w_v+xw[6]*xw_v\n",
        "y_h8=bi[7]+c[7]*x+b[7]*m+w[7]*w_v+xw[7]*xw_v\n",
        "y_h9=bi[8]+c[8]*x+b[8]*m+w[8]*w_v+xw[8]*xw_v\n"
      ],
      "metadata": {
        "id": "HP8oMx2fzK2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TSS = ((y-y.mean())**2).sum(axis=1).sum()\n",
        "SSR1 = ((y_h1-y.mean())**2).sum(axis=1).sum()\n",
        "SSE1 = ((y-y_h1)**2).sum(axis=1).sum()\n",
        "SSR2 = ((y_h2-y.mean())**2).sum(axis=1).sum()\n",
        "SSE2 = ((y-y_h2)**2).sum(axis=1).sum()\n",
        "SSR3 = ((y_h3-y.mean())**2).sum(axis=1).sum()\n",
        "SSE3 = ((y-y_h3)**2).sum(axis=1).sum()\n",
        "SSR4 = ((y_h4-y.mean())**2).sum(axis=1).sum()\n",
        "SSE4 = ((y-y_h4)**2).sum(axis=1).sum()\n",
        "SSR5 = ((y_h5-y.mean())**2).sum(axis=1).sum()\n",
        "SSE5 = ((y-y_h5)**2).sum(axis=1).sum()\n",
        "SSR6 = ((y_h6-y.mean())**2).sum(axis=1).sum()\n",
        "SSE6 = ((y-y_h6)**2).sum(axis=1).sum()\n",
        "SSR7 = ((y_h7-y.mean())**2).sum(axis=1).sum()\n",
        "SSE7 = ((y-y_h7)**2).sum(axis=1).sum()\n",
        "SSR8 = ((y_h8-y.mean())**2).sum(axis=1).sum()\n",
        "SSE8 = ((y-y_h8)**2).sum(axis=1).sum()\n",
        "SSR9 = ((y_h9-y.mean())**2).sum(axis=1).sum()\n",
        "SSE9 = ((y-y_h9)**2).sum(axis=1).sum()\n"
      ],
      "metadata": {
        "id": "8Aq0HgBVzNnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R2_1 = 1 - SSE1 / TSS\n",
        "print(R2_1)\n",
        "R2_2 = 1 - SSE2 / TSS\n",
        "print(R2_2)\n",
        "R2_3 = 1 - SSE3 / TSS\n",
        "print(R2_3)\n",
        "R2_4 = 1 - SSE4 / TSS\n",
        "print(R2_4)\n",
        "R2_5 = 1 - SSE5 / TSS\n",
        "print(R2_5)\n",
        "R2_6 = 1 - SSE6 / TSS\n",
        "print(R2_6)\n",
        "R2_7 = 1 - SSE7 / TSS\n",
        "print(R2_7)\n",
        "R2_8 = 1 - SSE8 / TSS\n",
        "print(R2_8)\n",
        "R2_9 = 1 - SSE9 / TSS\n",
        "print(R2_9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4d6f62-30ce-4bf9-ea2a-4d9ebd77f9cf",
        "id": "e7xSqm7ZzPGU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.1012834647691592\n",
            "0.14500367465106567\n",
            "0.2690302319804322\n",
            "0.3386046064045316\n",
            "0.38304785544399544\n",
            "0.4146505763372952\n",
            "0.4390774018685867\n",
            "0.45911752053563715\n",
            "0.47623073839394314\n"
          ]
        }
      ]
    }
  ]
}